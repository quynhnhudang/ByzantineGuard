{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d2ac995-c1fb-41d3-9f7a-810a94e7b70b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T19:09:35.859309Z",
     "iopub.status.busy": "2023-09-27T19:09:35.858427Z",
     "iopub.status.idle": "2023-09-27T19:09:35.875393Z",
     "shell.execute_reply": "2023-09-27T19:09:35.873965Z",
     "shell.execute_reply.started": "2023-09-27T19:09:35.859259Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/data/longdang/adversarial-train-ParallelComp'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03689429-2729-476f-823f-05353691b6b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T19:09:35.877605Z",
     "iopub.status.busy": "2023-09-27T19:09:35.877172Z",
     "iopub.status.idle": "2023-09-27T19:09:35.904006Z",
     "shell.execute_reply": "2023-09-27T19:09:35.902653Z",
     "shell.execute_reply.started": "2023-09-27T19:09:35.877561Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/longdang/FedShare\n"
     ]
    }
   ],
   "source": [
    "%cd /storage2-mnt/data/longdang/FedShare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c43256af-1b39-49ab-a87d-0152161f811a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T19:09:35.905446Z",
     "iopub.status.busy": "2023-09-27T19:09:35.905072Z",
     "iopub.status.idle": "2023-09-27T19:09:35.917892Z",
     "shell.execute_reply": "2023-09-27T19:09:35.916585Z",
     "shell.execute_reply.started": "2023-09-27T19:09:35.905406Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/data/longdang/FedShare'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48a0fc9-2ca2-48dc-b6cd-f5dc28c1ad5c",
   "metadata": {},
   "source": [
    "# Requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4daa553-e4d7-40f2-97ff-0e896139d630",
   "metadata": {},
   "source": [
    "1. python 3.7.6\n",
    "2. torch 13.1\n",
    "3. matplotlib\n",
    "4. h5py\n",
    "5. tqdm\n",
    "6. ipykernel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4497b4a2-4c88-42bc-9cc3-1511efef9ec3",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3599eefe-3cb3-4b1b-afe0-5417e6007d5d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T19:09:35.920739Z",
     "iopub.status.busy": "2023-09-27T19:09:35.920349Z",
     "iopub.status.idle": "2023-09-27T19:09:39.109543Z",
     "shell.execute_reply": "2023-09-27T19:09:39.108809Z",
     "shell.execute_reply.started": "2023-09-27T19:09:35.920698Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/l/longdang/.conda/envs/torch_13/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn \n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader, Dataset, Subset, ConcatDataset\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn #ChatGPT: optimize the performance of convolutional neural network computations on NVIDIA GPUs\n",
    "\n",
    "import copy\n",
    "import numpy as np\n",
    "from numpy import linalg as LA\n",
    "import random\n",
    "from tqdm import trange\n",
    "import h5py\n",
    "\n",
    "from utils.sampling import iid\n",
    "from utils.options import args_parser\n",
    "\n",
    "from src.nets import MLP, CNN_v1, CNN_v2, CNN_v3, Alexnet, get_model\n",
    "from src.strategy import FedAvg\n",
    "# from src.test import test_img\n",
    "from src.attack import visualize_adversarial_images\n",
    "from src.resnet import ResNet18\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# matplotlib.use('Agg')\n",
    "# plt.style.use('seaborn')\n",
    "# plt.rcParams.update({'lines.markeredgewidth': 1})\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import math\n",
    "from PIL import Image\n",
    "import itertools\n",
    "import collections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34f9ddd-3619-4a50-baec-f7d8ac51e8e7",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "# class Args - Change 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b7e5fa8-a7af-4e2e-91f0-31c73786a272",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T19:09:39.112808Z",
     "iopub.status.busy": "2023-09-27T19:09:39.110598Z",
     "iopub.status.idle": "2023-09-27T19:09:39.156522Z",
     "shell.execute_reply": "2023-09-27T19:09:39.155230Z",
     "shell.execute_reply.started": "2023-09-27T19:09:39.112778Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Args:\n",
    "    fed = 'Krum'\n",
    "    rounds = 2\n",
    "    num_users = 5 #1 user\n",
    "    frac = 1\n",
    "    local_ep = 1 #increase next or K in the paper\n",
    "    min_le = 5\n",
    "    max_le = 15\n",
    "    local_bs = 128\n",
    "    bs = 128 #test batch size\n",
    "    lr = 0.001\n",
    "    global_lr = 1 #SCAFFOLD \n",
    "    momentum = 0.9\n",
    "    classwise = 1000 #maximum sharing 10,000 images.\n",
    "    alpha = 0\n",
    "    adv_eps = 0.031\n",
    "    l2_lambda = 0.0002\n",
    "    ##########################\n",
    "    dataset = 'cifar'\n",
    "    # dataset = 'cifar'\n",
    "    model='customized_resnet18'\n",
    "    sampling= 'iid'\n",
    "    num_classes=10\n",
    "    num_channels=3\n",
    "    gpu=0\n",
    "    verbose=True\n",
    "    seed=123\n",
    "    all_clients=True\n",
    "    sys_homo=True\n",
    "    debug=True\n",
    "    device = torch.device('cuda:{}'.format(gpu) if torch.cuda.is_available() and gpu != -1 else 'cpu')\n",
    "    soft_label_clean = 0.95\n",
    "    mean = 0\n",
    "    sigma = 0.0001\n",
    "    rho = 0.1\n",
    "    #PGD\n",
    "    eps=0.0314\n",
    "    nb_iter=7\n",
    "    eps_iter=0.00784\n",
    "    clip_min=0.0\n",
    "    clip_max=1.0\n",
    "    #FGSM\n",
    "    eps_FGSM = 0.031\n",
    "    adv_global_train_file_name='/data/longdang/FedShare/data/Adv_data/CW/cifar10/adversarial_examples_train_cifar10_3.pkl'\n",
    "    adv_global_test_file_name='/data/longdang/FedShare/data/Adv_data/CW/cifar10/adversarial_examples_test_cifar10_3.pkl'\n",
    "    #Krum\n",
    "    byzantine_threshold=2\n",
    "args=Args()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c06cf44-06f3-47fd-8294-bd84f0a83bc1",
   "metadata": {},
   "source": [
    "# Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a14c5558-752d-4a03-b0d6-aa9c596b2a28",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T19:09:39.157914Z",
     "iopub.status.busy": "2023-09-27T19:09:39.157565Z",
     "iopub.status.idle": "2023-09-27T19:09:39.170450Z",
     "shell.execute_reply": "2023-09-27T19:09:39.169327Z",
     "shell.execute_reply.started": "2023-09-27T19:09:39.157874Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da60725-7f73-41bc-8fa6-855b78c874d6",
   "metadata": {},
   "source": [
    "# Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "003cc2bc-b150-413b-b69f-25a50d6111df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T19:09:39.171786Z",
     "iopub.status.busy": "2023-09-27T19:09:39.171428Z",
     "iopub.status.idle": "2023-09-27T19:09:39.186974Z",
     "shell.execute_reply": "2023-09-27T19:09:39.186309Z",
     "shell.execute_reply.started": "2023-09-27T19:09:39.171748Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "random.seed(args.seed)\n",
    "np.random.seed(args.seed)\n",
    "torch.manual_seed(args.seed)     \n",
    "torch.cuda.manual_seed_all(args.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126d8bff-fa85-4e88-a8bf-bc6f34de7409",
   "metadata": {},
   "source": [
    "# Load dataset and split users"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d045336f-562d-4cd0-a267-da74c0580506",
   "metadata": {},
   "source": [
    "### train_dg_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "effbd25e-b989-4ea0-9ca5-050fb5b6257d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T19:09:39.188112Z",
     "iopub.status.busy": "2023-09-27T19:09:39.187773Z",
     "iopub.status.idle": "2023-09-27T19:09:39.198112Z",
     "shell.execute_reply": "2023-09-27T19:09:39.196990Z",
     "shell.execute_reply.started": "2023-09-27T19:09:39.188077Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_dg_split(dataset, args): \n",
    "    dg_idx = []\n",
    "    train_idx = []\n",
    "    idxs = np.arange(len(dataset))\n",
    "\n",
    "    if args.dataset == \"mnist\":\n",
    "        labels = dataset.targets.numpy()\n",
    "    elif args.dataset == \"cifar\":\n",
    "        labels = np.array(dataset.targets)\n",
    "    else:\n",
    "        exit('Error: unrecognized dataset')\n",
    "    \n",
    "    # sort labels\n",
    "    idxs_labels = np.vstack((idxs, labels))\n",
    "    idxs_labels = idxs_labels[:,idxs_labels[1,:].argsort()]\n",
    "    \n",
    "    #add some adjustment \n",
    "    \n",
    "    idxs = idxs_labels[0]\n",
    "    labels = idxs_labels[1]\n",
    "    \n",
    "    #for all classes\n",
    "    for i in range(args.num_classes):\n",
    "        specific_class = np.extract(labels == i, idxs)\n",
    "        \n",
    "        # uniformly assign the particular class (args.classwise) to the global dataset\n",
    "        dg = np.random.choice(specific_class, args.classwise, replace=False)\n",
    "        \n",
    "        # divide and split the datata into the global dataset and all parties' dataset\n",
    "        train_tmp = set(specific_class)-set(dg)\n",
    "        \n",
    "        dg_idx = dg_idx + list(dg)\n",
    "        \n",
    "        train_idx = train_idx + list(train_tmp)\n",
    "    \n",
    "    return dg_idx, train_idx "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab3c0906-60ab-423a-b5cc-532499dcb174",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T19:09:39.199381Z",
     "iopub.status.busy": "2023-09-27T19:09:39.199031Z",
     "iopub.status.idle": "2023-09-27T19:09:39.212729Z",
     "shell.execute_reply": "2023-09-27T19:09:39.212043Z",
     "shell.execute_reply.started": "2023-09-27T19:09:39.199343Z"
    }
   },
   "outputs": [],
   "source": [
    "def noniid(dataset, args):\n",
    "    \"\"\"\n",
    "    Sample non-I.I.D client data from dataset\n",
    "    -> Different clients can hold vastly different amounts of data\n",
    "    :param dataset:\n",
    "    :param num_users:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    num_dataset = len(dataset)\n",
    "    idx = np.arange(num_dataset)\n",
    "    dict_users = {i: list() for i in range(args.num_users)}\n",
    "    \n",
    "    min_num = int(num_dataset/args.num_users)\n",
    "    max_num = int(num_dataset/args.num_users)\n",
    "\n",
    "    random_num_size = np.random.randint(min_num, max_num+1, size=args.num_users)\n",
    "    print(f\"Total number of datasets owned by clients : {sum(random_num_size)}\")\n",
    "\n",
    "    # total dataset should be larger or equal to sum of splitted dataset.\n",
    "    assert num_dataset >= sum(random_num_size)\n",
    "\n",
    "    # divide and assign\n",
    "    for i, rand_num in enumerate(random_num_size):\n",
    "\n",
    "        rand_set = set(np.random.choice(idx, rand_num, replace=False))\n",
    "        idx = list(set(idx) - rand_set)\n",
    "        dict_users[i] = rand_set\n",
    "\n",
    "    return dict_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b7f9b62b-4e6c-4ac3-8f18-90348cdcb6d9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T19:09:39.217800Z",
     "iopub.status.busy": "2023-09-27T19:09:39.217196Z",
     "iopub.status.idle": "2023-09-27T19:09:39.227705Z",
     "shell.execute_reply": "2023-09-27T19:09:39.226957Z",
     "shell.execute_reply.started": "2023-09-27T19:09:39.217762Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def print_statistics(i, y_train_pi, nb_labels=10):\n",
    "    print('Party_', i)\n",
    "    for l in range(nb_labels):\n",
    "        print('* Label ', l, ' samples: ', (y_train_pi == l).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a0c205-d176-4a0e-b3a8-5bfc28c7e69d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### CustomTensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "732e291a-820e-4ebc-8c2f-42317ce6b501",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T19:09:39.229197Z",
     "iopub.status.busy": "2023-09-27T19:09:39.228848Z",
     "iopub.status.idle": "2023-09-27T19:09:39.242107Z",
     "shell.execute_reply": "2023-09-27T19:09:39.241410Z",
     "shell.execute_reply.started": "2023-09-27T19:09:39.229160Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CustomTensorDataset(Dataset):\n",
    "    # adv_train_dataset = CustomTensorDataset(train_concatenated_array, \n",
    "    #                                         train_reshaped_labels, \n",
    "    #                                         transform_list=train_transform)\n",
    "\n",
    "    def __init__(self, data_X, data_y, transform_list=None):\n",
    "        '''\n",
    "        data_X: numpy array, shape (50000, 3, 32, 32).\n",
    "        data_Y: python list, shape (50000,)\n",
    "        \n",
    "        '''\n",
    "        self.data = data_X\n",
    "        self.targets = data_y\n",
    "        \n",
    "        self.data = self.data.transpose((0, 2, 3, 1))  # convert to HWC\n",
    "\n",
    "        X_tensor, y_tensor = torch.tensor(self.data), torch.tensor(self.targets)\n",
    "        \n",
    "        tensors = (X_tensor, y_tensor)\n",
    "\n",
    "        assert all(tensors[0].size(0) == tensor.size(0) for tensor in tensors)\n",
    "\n",
    "        self.tensors = tensors #depends on self.data and self.targets\n",
    "        self.transforms = transform_list\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "     \n",
    "        img, target = self.data[index], self.targets[index]\n",
    "\n",
    "        if self.transforms:\n",
    "          #for transform in self.transforms: \n",
    "            img = self.transforms(img)\n",
    "\n",
    "        # y = self.tensors[1][index]\n",
    "\n",
    "        return img, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data) #For a numpy. ndarray , len() returns the size of the first dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d5449f0-66b3-47ec-8ea7-1fab01d45663",
   "metadata": {},
   "source": [
    "### class NumpyDataSet2TorchDataset(Dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "55398c4b-4c93-45c8-b9a0-67dea89bcc77",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T19:09:39.243601Z",
     "iopub.status.busy": "2023-09-27T19:09:39.243223Z",
     "iopub.status.idle": "2023-09-27T19:09:39.256877Z",
     "shell.execute_reply": "2023-09-27T19:09:39.255931Z",
     "shell.execute_reply.started": "2023-09-27T19:09:39.243562Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class NumpyDataSet2TorchDataset(Dataset):\n",
    "    # adv_train_dataset = CustomTensorDataset(train_concatenated_array, \n",
    "    #                                         train_reshaped_labels, \n",
    "    #                                         transform_list=train_transform)\n",
    "\n",
    "    def __init__(self, data_X, data_y, transform_list=None):\n",
    "        '''\n",
    "        data_X: numpy array, shape (40000, 32, 32, 3).\n",
    "        data_Y: numpy array, shape (40000, 10)\n",
    "        \n",
    "        '''\n",
    "        self.data = data_X\n",
    "        self.targets = np.argmax(data_y, axis=1).tolist() # Return a Python list\n",
    "              \n",
    "        self.transforms = transform_list\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "     \n",
    "        img, target = self.data[index], self.targets[index]\n",
    "       \n",
    "        # Check the data type of the array\n",
    "        # Add 0.5 after unnormalizing to [0, 255] to round to nearest integer\n",
    "        img = np.clip(img * 255 + 0.5, 0, 255).astype(np.uint8)\n",
    "        \n",
    "        # doing this so that it is consistent with all other datasets\n",
    "        # to return a PIL Image                                \n",
    "        img = Image.fromarray(img)\n",
    "\n",
    "        if self.transforms:\n",
    "          #for transform in self.transforms: \n",
    "            img = self.transforms(img)\n",
    "\n",
    "        # y = self.tensors[1][index]\n",
    "\n",
    "        return img, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c457f6af-024f-4898-a96e-34ead77fbf58",
   "metadata": {},
   "source": [
    "## Load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "292401d6-74d7-4f7b-9312-b30ef9e17053",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T19:09:39.258151Z",
     "iopub.status.busy": "2023-09-27T19:09:39.257832Z",
     "iopub.status.idle": "2023-09-27T19:09:39.278963Z",
     "shell.execute_reply": "2023-09-27T19:09:39.278241Z",
     "shell.execute_reply.started": "2023-09-27T19:09:39.258120Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_dataset(args):\n",
    "    '''\n",
    "    outputs---\n",
    "    1) dataset: the original dataset before sharing \n",
    "    type: torchvision.datasets.cifar.CIFAR10\n",
    "    2) dataset_test: the global dataset for testing\n",
    "    type: torchvision.datasets.cifar.CIFAR10 \n",
    "    3) dg_idx: a list of image indices for sharing \n",
    "    type: Python list\n",
    "    4) dg: the global data sharing dataset\n",
    "    type: torchvision.datasets.cifar.CIFAR10\n",
    "    5) dataset_train: the total local data sharing dataset \n",
    "    type: torchvision.datasets.cifar.CIFAR10\n",
    "    6) dict_users: a dictionary of client id - a list of client's example indices\n",
    "    type: Python dictionary\n",
    "    '''\n",
    "    if args.dataset == 'mnist':\n",
    "        trans_mnist = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "        dataset = datasets.MNIST('../data/mnist/', train=True, download=True, transform=trans_mnist)\n",
    "        dataset_test = datasets.MNIST('../data/mnist/', train=False, download=True, transform=trans_mnist)\n",
    "    \n",
    "    elif args.dataset == 'cifar':\n",
    "        transform_train = transforms.Compose([\n",
    "                                            transforms.RandomCrop(32, padding=4),\n",
    "                                            transforms.RandomHorizontalFlip(),\n",
    "                                          transforms.ToTensor()])\n",
    "        \n",
    "        transform_test = transforms.Compose([ transforms.ToTensor(),\n",
    "        ])\n",
    "        dataset = datasets.CIFAR10('../data/cifar', train=True, download=True, \n",
    "                                   transform=transform_train)  \n",
    "        dataset_test = datasets.CIFAR10('../data/cifar', train=False, download=True, \n",
    "                                        transform=transform_test)\n",
    "        print(f\"total clean training images: {len(dataset)}\")\n",
    "        print(f\"total clean test images: {len(dataset_test)}\")\n",
    "    else:\n",
    "        exit('Error: unrecognized dataset')\n",
    "    \n",
    "    # Make a copy of the original dataset\n",
    "    dg = copy.deepcopy(dataset)\n",
    "    dataset_train = copy.deepcopy(dataset)\n",
    "    \n",
    "    # selected indices for sharing. The rest for training.\n",
    "    # dg_idx, dataset_train_idx = train_dg_split(dataset, args)\n",
    "    dg_idx, dataset_train_idx = np.arange(len(dg)), np.arange(len(dataset_train))\n",
    "    \n",
    "    # Pixels based on dg_idx, dataset_train_idx\n",
    "    dg.data, dataset_train.data = dataset.data[dg_idx], \\\n",
    "                                  dataset.data[dataset_train_idx]\n",
    "    \n",
    "    #labels\n",
    "    if args.dataset == 'cifar':\n",
    "        dg.targets.clear()\n",
    "        dataset_train.targets.clear()\n",
    "        # Labels based on dg_idx\n",
    "        dg.targets = [dataset[i][1] for i in dg_idx]\n",
    "\n",
    "        # Labels based on dataset_train_idx   \n",
    "        dataset_train.targets = [dataset[i][1] for i in dataset_train_idx]\n",
    "    else:\n",
    "        dg.targets, dataset_train.targets = dataset.targets[dg_idx], \\\n",
    "                                            dataset.targets[dataset_train_idx]\n",
    "\n",
    "    # sample users, dataset_train\n",
    "    if args.sampling == 'iid':\n",
    "        dict_users = iid(dataset_train, args.num_users)\n",
    "    elif args.sampling == 'noniid':\n",
    "        dict_users = noniid(dataset_train, args)\n",
    "    else:\n",
    "        exit('Error: unrecognized sampling')\n",
    "    return dataset, dataset_test, dg_idx, dg, dataset_train, dict_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2f0f78fc-d14e-4bbb-afde-3cdd6a3879be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T19:09:39.281311Z",
     "iopub.status.busy": "2023-09-27T19:09:39.280965Z",
     "iopub.status.idle": "2023-09-27T19:09:39.290267Z",
     "shell.execute_reply": "2023-09-27T19:09:39.289548Z",
     "shell.execute_reply.started": "2023-09-27T19:09:39.281275Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# args.num_users = 10 #1 user\n",
    "# args.sampling= 'iid'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b7ae20-e45a-4c5c-91fa-f50f6fdfed17",
   "metadata": {},
   "source": [
    "#### Run load_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41cdbbbc-9aed-4812-b07e-8cca10d570d2",
   "metadata": {},
   "source": [
    "##### class CIFAR10(VisionDataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "beb9c533-9c2b-48de-bb2e-dc33bd23c6e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T19:09:39.291633Z",
     "iopub.status.busy": "2023-09-27T19:09:39.291346Z",
     "iopub.status.idle": "2023-09-27T19:09:39.303547Z",
     "shell.execute_reply": "2023-09-27T19:09:39.302878Z",
     "shell.execute_reply.started": "2023-09-27T19:09:39.291610Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import os.path\n",
    "# import pickle\n",
    "# from typing import Any, Callable, Optional, Tuple\n",
    "\n",
    "# import numpy as np\n",
    "# from PIL import Image\n",
    "\n",
    "# from torchvision.datasets.utils import check_integrity, download_and_extract_archive\n",
    "# from torchvision.datasets.vision import VisionDataset\n",
    "\n",
    "\n",
    "# class MyCIFAR10(VisionDataset):\n",
    "#     \"\"\"`CIFAR10 <https://www.cs.toronto.edu/~kriz/cifar.html>`_ Dataset.\n",
    "\n",
    "#     Args:\n",
    "#         root (string): Root directory of dataset where directory\n",
    "#             ``cifar-10-batches-py`` exists or will be saved to if download is set to True.\n",
    "#         train (bool, optional): If True, creates dataset from training set, otherwise\n",
    "#             creates from test set.\n",
    "#         transform (callable, optional): A function/transform that takes in an PIL image\n",
    "#             and returns a transformed version. E.g, ``transforms.RandomCrop``\n",
    "#         target_transform (callable, optional): A function/transform that takes in the\n",
    "#             target and transforms it.\n",
    "#         download (bool, optional): If true, downloads the dataset from the internet and\n",
    "#             puts it in root directory. If dataset is already downloaded, it is not\n",
    "#             downloaded again.\n",
    "\n",
    "#     \"\"\"\n",
    "\n",
    "#     base_folder = \"cifar-10-batches-py\"\n",
    "#     url = \"https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\"\n",
    "#     filename = \"cifar-10-python.tar.gz\"\n",
    "#     tgz_md5 = \"c58f30108f718f92721af3b95e74349a\"\n",
    "#     train_list = [\n",
    "#         [\"data_batch_1\", \"c99cafc152244af753f735de768cd75f\"],\n",
    "#         [\"data_batch_2\", \"d4bba439e000b95fd0a9bffe97cbabec\"],\n",
    "#         [\"data_batch_3\", \"54ebc095f3ab1f0389bbae665268c751\"],\n",
    "#         [\"data_batch_4\", \"634d18415352ddfa80567beed471001a\"],\n",
    "#         [\"data_batch_5\", \"482c414d41f54cd18b22e5b47cb7c3cb\"],\n",
    "#     ]\n",
    "\n",
    "#     test_list = [\n",
    "#         [\"test_batch\", \"40351d587109b95175f43aff81a1287e\"],\n",
    "#     ]\n",
    "#     meta = {\n",
    "#         \"filename\": \"batches.meta\",\n",
    "#         \"key\": \"label_names\",\n",
    "#         \"md5\": \"5ff9c542aee3614f3951f8cda6e48888\",\n",
    "#     }\n",
    "\n",
    "#     def __init__(\n",
    "#         self,\n",
    "#         root: str,\n",
    "#         train: bool = True,\n",
    "#         transform: Optional[Callable] = None,\n",
    "#         target_transform: Optional[Callable] = None,\n",
    "#         download: bool = False,\n",
    "#     ) -> None:\n",
    "\n",
    "#         super().__init__(root, transform=transform, target_transform=target_transform)\n",
    "\n",
    "#         self.train = train  # training set or test set\n",
    "\n",
    "#         if download:\n",
    "#             self.download()\n",
    "\n",
    "#         if not self._check_integrity():\n",
    "#             raise RuntimeError(\"Dataset not found or corrupted. You can use download=True to download it\")\n",
    "\n",
    "#         if self.train:\n",
    "#             downloaded_list = self.train_list\n",
    "#         else:\n",
    "#             downloaded_list = self.test_list\n",
    "\n",
    "#         self.data: Any = []\n",
    "#         self.targets = []\n",
    "\n",
    "#         # now load the picked numpy arrays\n",
    "#         for file_name, checksum in downloaded_list:\n",
    "#             file_path = os.path.join(self.root, self.base_folder, file_name)\n",
    "#             with open(file_path, \"rb\") as f:\n",
    "#                 entry = pickle.load(f, encoding=\"latin1\")\n",
    "#                 self.data.append(entry[\"data\"])\n",
    "#                 if \"labels\" in entry:\n",
    "#                     self.targets.extend(entry[\"labels\"])\n",
    "#                 else:\n",
    "#                     self.targets.extend(entry[\"fine_labels\"])\n",
    "\n",
    "#         self.data = np.vstack(self.data).reshape(-1, 3, 32, 32)\n",
    "#         self.data = self.data.transpose((0, 2, 3, 1))  # convert to HWC\n",
    "\n",
    "#         self._load_meta()\n",
    "\n",
    "#     def _load_meta(self) -> None:\n",
    "#         path = os.path.join(self.root, self.base_folder, self.meta[\"filename\"])\n",
    "#         if not check_integrity(path, self.meta[\"md5\"]):\n",
    "#             raise RuntimeError(\"Dataset metadata file not found or corrupted. You can use download=True to download it\")\n",
    "#         with open(path, \"rb\") as infile:\n",
    "#             data = pickle.load(infile, encoding=\"latin1\")\n",
    "#             self.classes = data[self.meta[\"key\"]]\n",
    "#         self.class_to_idx = {_class: i for i, _class in enumerate(self.classes)}\n",
    "\n",
    "#     def __getitem__(self, index: int) -> Tuple[Any, Any]:\n",
    "#         \"\"\"\n",
    "#         Args:\n",
    "#             index (int): Index\n",
    "\n",
    "#         Returns:\n",
    "#             tuple: (image, target) where target is index of the target class.\n",
    "#         \"\"\"\n",
    "#         img, target = self.data[index], self.targets[index]\n",
    "        \n",
    "#         # Check the data type of the array\n",
    "#         print(f'img.shape {img.shape} ')\n",
    "#         print(f'type(img) {type(img)}')\n",
    "#         data_type = img.dtype\n",
    "#         print(\"Data type:\", data_type)\n",
    "       \n",
    "        \n",
    "        \n",
    "#         # Calculate minimum and maximum values along each channel (axis 2)\n",
    "#         min_values_per_channel = np.min(img, axis=(0, 1))\n",
    "#         max_values_per_channel = np.max(img, axis=(0, 1))\n",
    "\n",
    "#         # Calculate global minimum and maximum values\n",
    "#         global_min_value = np.min(img)\n",
    "#         global_max_value = np.max(img)\n",
    "\n",
    "#         print(\"Minimum values per channel:\", min_values_per_channel)\n",
    "#         print(\"Maximum values per channel:\", max_values_per_channel)\n",
    "#         print(\"Global minimum value:\", global_min_value)\n",
    "#         print(\"Global maximum value:\", global_max_value)\n",
    "       \n",
    "        \n",
    "        \n",
    "#         # doing this so that it is consistent with all other datasets\n",
    "#         # to return a PIL Image\n",
    "#         img = Image.fromarray(img)\n",
    "        \n",
    "#         if self.transform is not None:\n",
    "#             img = self.transform(img)\n",
    "\n",
    "#         if self.target_transform is not None:\n",
    "#             target = self.target_transform(target)\n",
    "\n",
    "#         return img, target\n",
    "\n",
    "#     def __len__(self) -> int:\n",
    "#         return len(self.data)\n",
    "\n",
    "#     def _check_integrity(self) -> bool:\n",
    "#         for filename, md5 in self.train_list + self.test_list:\n",
    "#             fpath = os.path.join(self.root, self.base_folder, filename)\n",
    "#             if not check_integrity(fpath, md5):\n",
    "#                 return False\n",
    "#         return True\n",
    "\n",
    "#     def download(self) -> None:\n",
    "#         if self._check_integrity():\n",
    "#             print(\"Files already downloaded and verified\")\n",
    "#             return\n",
    "#         download_and_extract_archive(self.url, self.root, filename=self.filename, md5=self.tgz_md5)\n",
    "\n",
    "#     def extra_repr(self) -> str:\n",
    "#         split = \"Train\" if self.train is True else \"Test\"\n",
    "#         return f\"Split: {split}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496a6c4a-8cbb-45ea-8674-1ab9ba563803",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Load the clean dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6205dce4-f4eb-4cd2-b3c6-d6f4543b1dcc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T19:09:39.305030Z",
     "iopub.status.busy": "2023-09-27T19:09:39.304680Z",
     "iopub.status.idle": "2023-09-27T19:10:09.510566Z",
     "shell.execute_reply": "2023-09-27T19:10:09.509565Z",
     "shell.execute_reply.started": "2023-09-27T19:09:39.304993Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "total clean training images: 50000\n",
      "total clean test images: 10000\n"
     ]
    }
   ],
   "source": [
    "args.dataset='cifar'\n",
    "dataset, dataset_test, dg_idx, dg, dataset_train, dict_users = load_dataset(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bbd3341e-d1f5-40e5-995d-cd2995acc42d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T19:10:09.512463Z",
     "iopub.status.busy": "2023-09-27T19:10:09.512094Z",
     "iopub.status.idle": "2023-09-27T19:10:09.520604Z",
     "shell.execute_reply": "2023-09-27T19:10:09.519444Z",
     "shell.execute_reply.started": "2023-09-27T19:10:09.512425Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "party0 local: 10000\n",
      "party1 local: 10000\n",
      "party2 local: 10000\n",
      "party3 local: 10000\n",
      "party4 local: 10000\n"
     ]
    }
   ],
   "source": [
    "# share_idx = uniform_distribute(dg, args)\n",
    "for idx in range(args.num_users):\n",
    "    print(f'party{idx} local: {len(dict_users[idx])}')\n",
    "    # print(f'party{idx} share: {len(share_idx)}')\n",
    "    # local_train_idx = set(list(dict_users[idx]) + share_idx)\n",
    "    # print(f'party{idx} combined set (no repeat): {len(local_train_idx)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1615e1-9de5-45c8-a604-4964da17b0d4",
   "metadata": {},
   "source": [
    "# Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "71520358-9e50-4a7c-99b7-26b435641918",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T19:10:09.521911Z",
     "iopub.status.busy": "2023-09-27T19:10:09.521570Z",
     "iopub.status.idle": "2023-09-27T19:10:09.535127Z",
     "shell.execute_reply": "2023-09-27T19:10:09.533936Z",
     "shell.execute_reply.started": "2023-09-27T19:10:09.521875Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_model(args, img_size):\n",
    "    \"\"\"\n",
    "    Builds a neural network model based on command line arguments and image size.\n",
    "    Args:\n",
    "        args (argparse.Namespace): Command line arguments.\n",
    "        img_size (tuple): Size of the input images.\n",
    "    Returns:\n",
    "        A PyTorch model object.\n",
    "    \"\"\"\n",
    "    if args.model == 'cnn' and (args.dataset == 'cifar'):\n",
    "        net_glob = CNN_v2(args=args).to(args.device)\n",
    "    elif args.model == 'cnn' and args.dataset == 'mnist':\n",
    "        net_glob = CNN_v1(args=args).to(args.device)\n",
    "    elif args.model == 'mlp':\n",
    "        print('This is a model with two hidden layers')\n",
    "        len_in = img_size\n",
    "        net_glob = MLP(dim_in=len_in, dim_hidden=200, dim_out=args.num_classes).to(args.device)\n",
    "    elif args.model == 'CNN_v2_resume' and args.filepath is not None:\n",
    "        net_glob = CNN_v2(args=args)\n",
    "        print('filepath ', args.filepath)\n",
    "        weights = torch.load(args.filepath)\n",
    "        net_glob.load_state_dict(weights) \n",
    "        net_glob.to(args.device)\n",
    "    elif args.model == 'customized_resnet18':\n",
    "        print('This is customized_resnet18')\n",
    "        net_glob = ResNet18()\n",
    "        net_glob = net_glob.to(args.device)\n",
    "        net_glob = torch.nn.DataParallel(net_glob)\n",
    "        cudnn.benchmark = True\n",
    "    else:\n",
    "        net_glob = get_model(args.model)\n",
    "        for param in net_glob.parameters():\n",
    "            param.requires_grad = True #fixed feature extractor\n",
    "        num_ftrs = net_glob.fc.in_features\n",
    "        net_glob.fc = nn.Linear(num_ftrs, args.num_classes + 1)\n",
    "        net_glob.to(args.device)\n",
    "        \n",
    "    return net_glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9f393790-7123-4150-b129-8c3189a6955d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T19:10:09.536441Z",
     "iopub.status.busy": "2023-09-27T19:10:09.536104Z",
     "iopub.status.idle": "2023-09-27T19:10:09.550946Z",
     "shell.execute_reply": "2023-09-27T19:10:09.550077Z",
     "shell.execute_reply.started": "2023-09-27T19:10:09.536405Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 32, 3)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_size = dataset_train.data[0].shape\n",
    "img_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "24bc2371-4f5a-4e87-87f4-1e28e7970ee8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T19:10:09.552290Z",
     "iopub.status.busy": "2023-09-27T19:10:09.551936Z",
     "iopub.status.idle": "2023-09-27T19:10:11.015775Z",
     "shell.execute_reply": "2023-09-27T19:10:11.014703Z",
     "shell.execute_reply.started": "2023-09-27T19:10:09.552253Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 32, 32])\n",
      "This is customized_resnet18\n",
      "DataParallel(\n",
      "  (module): ResNet(\n",
      "    (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (layer1): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (shortcut): Sequential()\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (shortcut): Sequential()\n",
      "      )\n",
      "    )\n",
      "    (layer2): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (shortcut): Sequential(\n",
      "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (shortcut): Sequential()\n",
      "      )\n",
      "    )\n",
      "    (layer3): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (shortcut): Sequential(\n",
      "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (shortcut): Sequential()\n",
      "      )\n",
      "    )\n",
      "    (layer4): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (shortcut): Sequential(\n",
      "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (shortcut): Sequential()\n",
      "      )\n",
      "    )\n",
      "    (linear): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "img_size = dataset_train[0][0].shape\n",
    "print(img_size)\n",
    "# build model\n",
    "net_glob = build_model(args, img_size)\n",
    "\n",
    "print(net_glob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b4259020-837c-440c-af57-70af05fb229f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T19:10:11.017218Z",
     "iopub.status.busy": "2023-09-27T19:10:11.016868Z",
     "iopub.status.idle": "2023-09-27T19:10:11.024755Z",
     "shell.execute_reply": "2023-09-27T19:10:11.023727Z",
     "shell.execute_reply.started": "2023-09-27T19:10:11.017178Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11173962\n"
     ]
    }
   ],
   "source": [
    "trainable_params = sum(\n",
    "\tp.numel() for p in net_glob.parameters() if p.requires_grad\n",
    ")\n",
    "print(trainable_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0c97af-c537-4e7e-82cf-c6f47a79e8dc",
   "metadata": {},
   "source": [
    "## Gaussian noise (output: 2 Python lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c3f8ee82-b730-4a9a-9661-8c66151220f0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T19:10:11.026110Z",
     "iopub.status.busy": "2023-09-27T19:10:11.025742Z",
     "iopub.status.idle": "2023-09-27T19:10:11.039243Z",
     "shell.execute_reply": "2023-09-27T19:10:11.038508Z",
     "shell.execute_reply.started": "2023-09-27T19:10:11.026070Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def Gaussian_adversarial_images(args, images, mean, std, min_val = 0, max_val = 1):\n",
    "    '''\n",
    "    Inputs:\n",
    "    images: torch.Size([batch size, 3, 32, 32])\n",
    "    type: Torch.Tensor\n",
    "    mean: the mean of the Gaussian noise to be added\n",
    "    std: the standard deviation of the Gaussian noise to be added\n",
    "    min_val: the minimum value of the images (default: 0)\n",
    "    max_val: the maximum value of the images (default: 1)\n",
    "    \n",
    "    Output:\n",
    "    images_list: a list of (C x H x W) channel first clean images \n",
    "    type: a list of Torch objects\n",
    "    images_adv_list: a list of (C x H x W) channel first adversarial images \n",
    "    type: a list of Torch objects\n",
    "    '''\n",
    "    images_adv_list = []\n",
    "    images_list = []\n",
    "        \n",
    "    #images = Variable(images,requires_grad = True)\n",
    "    noise = torch.normal(mean, std, size=images.shape).cuda()\n",
    "    \n",
    "    # add the noise to the images\n",
    "    images_adv = torch.clamp(images + noise, min=min_val, max=max_val)\n",
    "    \n",
    "    images_adv_list.extend(images_adv) #a list of Tensor\n",
    "    images_list.extend(images) #a list of Tensor\n",
    "    \n",
    "    return images_list, images_adv_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3345be0-edac-4eb8-8064-5b83135feb9d",
   "metadata": {},
   "source": [
    "## FGSM (output: 2 Python lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1054826e-c793-4989-8e18-8f65dda2dc41",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T19:10:11.040731Z",
     "iopub.status.busy": "2023-09-27T19:10:11.040371Z",
     "iopub.status.idle": "2023-09-27T19:10:11.054420Z",
     "shell.execute_reply": "2023-09-27T19:10:11.053759Z",
     "shell.execute_reply.started": "2023-09-27T19:10:11.040694Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def FGSM(args, model, criterion, images, labels, epsilon = 8/255, min_val = 0,max_val = 1):\n",
    "    '''\n",
    "    Inputs:\n",
    "    images: torch.Size([batch size, 3, 32, 32])\n",
    "    type: Torch.Tensor\n",
    "    labels: torch.Size([6, 11])\n",
    "    type: torch.Tensor\n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "    Output:\n",
    "    images_list: a list of (C x H x W) channel first clean images \n",
    "    type: a list of Torch objects\n",
    "    images_adv_list: a list of (C x H x W) channel first adversarial images \n",
    "    type: a list of Torch objects\n",
    "    '''\n",
    "    images_adv_list = []\n",
    "    images_list = []\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        images = images.cuda()\n",
    "        labels = labels.cuda()\n",
    "        \n",
    "        #images = Variable(images,requires_grad = True)\n",
    "    images.requires_grad = True\n",
    "    \n",
    "    outputs = model(images)\n",
    "    loss =criterion(outputs,labels)\n",
    "\n",
    "    model.zero_grad()\n",
    "    if images.grad is not None:\n",
    "        images.grad.data.fill_(0)\n",
    "    loss.backward()\n",
    "\n",
    "    grad = torch.sign(images.grad.data) # Take the sign of the gradient.\n",
    "    images_adv = torch.clamp(images.data + epsilon*grad,min_val,max_val)     # x_adv = x + epsilon*grad\n",
    "\n",
    "    # adverserial_images.extend((images_adv).cpu().data.numpy())\n",
    "    # images_list.extend(images.cpu().data.numpy())\n",
    "    \n",
    "    images_adv_list.extend(images_adv) #a list of Tensor\n",
    "    images_list.extend(images) #a list of Tensor\n",
    "    \n",
    "    return images_list, images_adv_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ad0959-9c51-4593-94e8-6d0a1f2b13f2",
   "metadata": {},
   "source": [
    "## FGSM noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "22ddd318-6400-4ab3-8b2e-9aec804e6d89",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T19:10:11.055828Z",
     "iopub.status.busy": "2023-09-27T19:10:11.055480Z",
     "iopub.status.idle": "2023-09-27T19:10:11.071676Z",
     "shell.execute_reply": "2023-09-27T19:10:11.070931Z",
     "shell.execute_reply.started": "2023-09-27T19:10:11.055791Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def FGSM_noise(args, model, criterion, images, labels, epsilon = 8/255,\n",
    "               mean=0, sigma=0.1, min_val = 0, max_val = 1):\n",
    "        \n",
    "    images_adv_list = []\n",
    "    images_list = []\n",
    "    # with torch.enable_grad():\n",
    "    if torch.cuda.is_available():\n",
    "        images = images.cuda()\n",
    "        labels = labels.cuda()\n",
    "    images.requires_grad = True\n",
    "\n",
    "    outputs = model(images)\n",
    "    loss=criterion(outputs,labels)\n",
    "\n",
    "    model.zero_grad()\n",
    "    if images.grad is not None:\n",
    "        images.grad.data.fill_(0)\n",
    "    loss.backward()\n",
    "\n",
    "    grad = torch.sign(images.grad.data) # Take the sign of the gradient.\n",
    "    images_adv = torch.clamp(images.data + epsilon*grad,min_val,max_val)     # x_adv = x + epsilon*grad\n",
    "    \n",
    "\n",
    "    noise = torch.normal(mean, sigma,size=images_adv.shape).to(args.device)\n",
    "    images_adv_noise = images_adv + noise\n",
    "    images_adv_noise = torch.clamp(images_adv_noise, min_val, max_val)\n",
    "    \n",
    "    images_adv_list.extend(images_adv) #a list of Tensor\n",
    "    images_list.extend(images) #a list of Tensor\n",
    "    \n",
    "    # noise_L2_norm = torch.norm(noise)\n",
    "    # print(f'noise_L2_norm: {type(noise_L2_norm)}') \n",
    "    # print(f'noise_L2_norm: {noise_L2_norm}') \n",
    "          \n",
    "    return images_list, images_adv_list    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9189bbac-880a-48b7-8d5b-cf13c5c4ce9c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## LinfPGDAttack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c0efb6a0-72d5-49d0-a04f-87e0542779c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T19:10:11.073028Z",
     "iopub.status.busy": "2023-09-27T19:10:11.072679Z",
     "iopub.status.idle": "2023-09-27T19:10:11.090197Z",
     "shell.execute_reply": "2023-09-27T19:10:11.089514Z",
     "shell.execute_reply.started": "2023-09-27T19:10:11.072991Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LinfPGDAttack(object):\n",
    "    '''\n",
    "    Input: tensors\n",
    "    Output: tensors\n",
    "    '''\n",
    "    def __init__(self, model, eps, nb_iter, eps_iter, clip_min, clip_max):\n",
    "        self.model = model\n",
    "        self.eps = eps\n",
    "        self.nb_iter = nb_iter\n",
    "        self.eps_iter = eps_iter\n",
    "        self.clip_min = clip_min\n",
    "        self.clip_max = clip_max\n",
    "\n",
    "\n",
    "    def perturb(self, x_natural, y):\n",
    "        x = x_natural.detach()\n",
    "        x = x + torch.zeros_like(x).uniform_(-self.eps, self.eps)\n",
    "        for i in range(self.nb_iter):\n",
    "            x.requires_grad_()\n",
    "            with torch.enable_grad():\n",
    "                logits = self.model(x)\n",
    "                loss = F.cross_entropy(logits, y)\n",
    "            grad = torch.autograd.grad(loss, [x])[0]\n",
    "            x = x.detach() + self.eps_iter * torch.sign(grad.detach())\n",
    "            x = torch.min(torch.max(x, x_natural - self.eps), x_natural + self.eps)\n",
    "            x = torch.clamp(x, self.clip_min, self.clip_max)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b2df68-f405-4395-8830-1833aa13d6f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-01T14:54:53.236672Z",
     "iopub.status.busy": "2023-03-01T14:54:53.236413Z",
     "iopub.status.idle": "2023-03-01T14:54:53.242801Z",
     "shell.execute_reply": "2023-03-01T14:54:53.241758Z",
     "shell.execute_reply.started": "2023-03-01T14:54:53.236640Z"
    },
    "tags": []
   },
   "source": [
    "## visualize_adversarial_images - Long test, remove y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "36ec3b19-4672-4935-a328-b75e54a6a961",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T19:10:11.091653Z",
     "iopub.status.busy": "2023-09-27T19:10:11.091299Z",
     "iopub.status.idle": "2023-09-27T19:10:11.110724Z",
     "shell.execute_reply": "2023-09-27T19:10:11.110019Z",
     "shell.execute_reply.started": "2023-09-27T19:10:11.091616Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def visualize_adversarial_images(args, round_cur, adversarial_images, y_preds, y_preds_adv, \n",
    "                                 images_list, label_list, epsilon):\n",
    "    if args.dataset == 'cifar' or args.dataset == 'ntga_cifar':\n",
    "        classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "        \n",
    "\n",
    "        adversarial_images = np.array(adversarial_images)\n",
    "        y_preds = np.array(y_preds)\n",
    "        y_preds_adv = np.array(y_preds_adv)\n",
    "        images_list = np.array(images_list)\n",
    "\n",
    "        c = adversarial_images - images_list  # Verify whether the max diff between the image and adversarial image is epsilon or not\n",
    "        if np.any(np.abs(c.max()) > epsilon + 0.01):\n",
    "            print('the difference is more than the epsilon')\n",
    "\n",
    "        \n",
    "        mean = np.array([0.5, 0.5, 0.5])\n",
    "        mean = mean[:, None, None]\n",
    "        std = np.array([0.5, 0.5, 0.5])\n",
    "        std = std[:, None, None]\n",
    "        \n",
    "\n",
    "        # Get index of all the images where the attack is successful\n",
    "        attack = (y_preds != y_preds_adv)\n",
    "        indexes = np.where(attack == True)[0]\n",
    "\n",
    "        # Plot the images\n",
    "        plt_idx = 0\n",
    "        while plt_idx < 2:\n",
    "            idx = np.random.choice(indexes)\n",
    "            img = images_list[idx]\n",
    "            adv_img = adversarial_images[idx]\n",
    "\n",
    "            img = img * std + mean\n",
    "            img = np.transpose(img, (1, 2, 0))\n",
    "            img = img.clip(0, 1)\n",
    "\n",
    "            adv_img = adv_img * std + mean\n",
    "            adv_img = np.transpose(adv_img, (1, 2, 0))\n",
    "            adv_img = adv_img.clip(0, 1)\n",
    "\n",
    "            noise = adv_img - img\n",
    "            noise = np.absolute(10 * noise)  # Noise is multiplied by 10 for visualization purpose\n",
    "            noise = noise.clip(0, 1)\n",
    "\n",
    "            if y_preds[idx] != y_preds_adv[idx]:\n",
    "                disp_im = np.concatenate((img, adv_img, noise), axis=1)\n",
    "                ax = plt.subplot(1, 2, plt_idx + 1)\n",
    "                ax.set_title(\"pred: {}, adv:{}\".format(classes[y_preds[idx]], classes[y_preds_adv[idx]]))\n",
    "                plt.imshow(disp_im)\n",
    "                plt.xticks([])\n",
    "                plt.yticks([])\n",
    "                plt_idx += 1\n",
    "                print(\"True Label: \", classes[label_list[idx]], \" \", \"Predicted Label:\", classes[y_preds[idx]], \" \",\n",
    "                      \"Adversarial Label:\", classes[y_preds_adv[idx]])\n",
    "        \n",
    "        name_file = f'./save/{args.fed}_{args.eps_FGSM}_{args.dataset}_{args.model}_{args.local_ep}_nParties_{len(idxs_users)}_{args.sampling}_{args.classwise}_{args.alpha}_round_cur_{round_cur}'\n",
    "        name_file_1 = name_file + '_visualization.pdf'\n",
    "        plt.savefig(name_file_1)\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642c0b21-eeda-4b91-896c-a94470e99cd2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-01T14:48:25.622591Z",
     "iopub.status.busy": "2023-03-01T14:48:25.622324Z",
     "iopub.status.idle": "2023-03-01T14:48:25.628536Z",
     "shell.execute_reply": "2023-03-01T14:48:25.627568Z",
     "shell.execute_reply.started": "2023-03-01T14:48:25.622560Z"
    },
    "tags": []
   },
   "source": [
    "# Test image methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066913dd-df62-4fe5-902d-49e941476c62",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-05T05:04:45.576517Z",
     "iopub.status.busy": "2023-03-05T05:04:45.576110Z",
     "iopub.status.idle": "2023-03-05T05:04:45.581097Z",
     "shell.execute_reply": "2023-03-05T05:04:45.579785Z",
     "shell.execute_reply.started": "2023-03-05T05:04:45.576491Z"
    },
    "tags": []
   },
   "source": [
    "### calculate_expected_perturbation_proportioncalculate_expected_perturbation_proportion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5cb62ba0-a4eb-4c56-a330-3ad577b3b754",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T19:10:11.112158Z",
     "iopub.status.busy": "2023-09-27T19:10:11.111810Z",
     "iopub.status.idle": "2023-09-27T19:10:11.128177Z",
     "shell.execute_reply": "2023-09-27T19:10:11.127207Z",
     "shell.execute_reply.started": "2023-09-27T19:10:11.112122Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_expected_perturbation_proportion(args, adversarial_images, images_list, delta = 1e-10):\n",
    "    \n",
    "    adversarial_images = torch.stack(adversarial_images).cpu().detach().numpy()\n",
    "    # print(adversarial_images.size())\n",
    "    images_list = torch.stack(images_list).cpu().detach().numpy() #detach\n",
    "        \n",
    "    adversarial_images = np.array(adversarial_images)\n",
    "    images_list = np.array(images_list)\n",
    "    \n",
    "    rho = np.zeros(len(images_list)) # record the size of perturbation (2-norm)\n",
    "    for i in range(len(images_list)):\n",
    "        diff = images_list[i]-adversarial_images[i]\n",
    "        \n",
    "        #L2-norm\n",
    "        if args.dataset == 'cifar' or args.dataset == 'cifar_cw_3' or args.dataset == 'ntga_cifar':\n",
    "            diff = diff.reshape((32*32,3))\n",
    "            \n",
    "        else:\n",
    "            diff = diff.reshape((28*28,1))\n",
    "\n",
    "        rho[i] = LA.norm(diff)/(LA.norm(images_list[i]) + delta)\n",
    "    #sum\n",
    "    rho =  np.sum(rho)\n",
    "    return rho"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f79c99-96fc-4d12-819a-dfd139656246",
   "metadata": {},
   "source": [
    "### Test method 1, no noise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0133623a-d6d7-44d3-9590-d832386563a4",
   "metadata": {},
   "source": [
    "#### DatasetSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6f1ff933-70b8-4706-974d-4bbaa7887624",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T19:10:11.136501Z",
     "iopub.status.busy": "2023-09-27T19:10:11.136024Z",
     "iopub.status.idle": "2023-09-27T19:10:11.144720Z",
     "shell.execute_reply": "2023-09-27T19:10:11.143728Z",
     "shell.execute_reply.started": "2023-09-27T19:10:11.136462Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DatasetSplit(Dataset):\n",
    "    def __init__(self, dataset, idxs):\n",
    "        self.dataset = dataset\n",
    "        self.idxs = list(idxs)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.idxs)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        image, label = self.dataset[self.idxs[item]]\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fb6d5dc2-1346-47eb-8a6a-b4ab9b49c53b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T19:10:11.146154Z",
     "iopub.status.busy": "2023-09-27T19:10:11.145802Z",
     "iopub.status.idle": "2023-09-27T19:10:11.166938Z",
     "shell.execute_reply": "2023-09-27T19:10:11.165998Z",
     "shell.execute_reply.started": "2023-09-27T19:10:11.146116Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test_img(net_g, datatest, idxs, args, criterion):\n",
    "    net_g.eval()\n",
    "    \n",
    "    # testing\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    adv_test_loss = 0\n",
    "    adv_correct = 0\n",
    "    adv_correct_2 = 0\n",
    "    misclassified = 0 #change decision\n",
    "    \n",
    "    #visualize\n",
    "    exp_adv_noise = 0\n",
    "    y_preds = []\n",
    "    y_preds_adv = []\n",
    "    test_images = []\n",
    "    test_label = []\n",
    "    adverserial_images = []\n",
    "\n",
    "    data_loader = DataLoader(DatasetSplit(datatest, idxs), batch_size=args.bs)\n",
    "    l = len(data_loader)\n",
    "    for idx, (data, target) in enumerate(data_loader):\n",
    "        #clean or any data load from the file\n",
    "        with torch.no_grad():\n",
    "        \n",
    "            if args.gpu != -1:\n",
    "                data, target = data.to(args.device), target.to(args.device) \n",
    "\n",
    "            log_probs = net_g(data)\n",
    "            # sum up batch loss\n",
    "            # test_loss += F.cross_entropy(log_probs, target, reduction='sum').item()\n",
    "            \n",
    "            # get the index of the max log-probability\n",
    "            y_pred = log_probs.data.max(1, keepdim=True)[1]\n",
    "            correct += y_pred.eq(target.data.view_as(y_pred)).long().cpu().sum()\n",
    "                \n",
    "        #FGSM method\n",
    "        images_list, images_adv_list = FGSM(args, net_g, criterion, data, target,\n",
    "                                                   args.eps_FGSM, args.clip_min, args.clip_max) #The adversarial_images list contains a series of perturbed images\n",
    "        \n",
    "        images_adv = torch.stack(images_adv_list) #return a tensor of size (args.bs, 3, 32, 32)\n",
    "        images_adv = images_adv.to(args.device)\n",
    "        \n",
    "        adv_noise = calculate_expected_perturbation_proportion(args, \n",
    "                                                               images_adv_list, \n",
    "                                                               images_list, \n",
    "                                                               1e-10)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            \n",
    "            log_probs = net_g(images_adv)\n",
    "            # sum up batch loss\n",
    "            # adv_test_loss += F.cross_entropy(log_probs, target, reduction='sum').item()\n",
    "            \n",
    "            # get the index of the max log-probability\n",
    "            adv_y_pred = log_probs.data.max(1, keepdim=True)[1]\n",
    "            adv_correct += adv_y_pred.eq(target.data.view_as(adv_y_pred)).long().cpu().sum()\n",
    "        \n",
    "        \n",
    "        misclassified += (y_pred != adv_y_pred).sum().item()\n",
    "        y_preds.extend(y_pred.cpu().data.numpy())\n",
    "        y_preds_adv.extend(adv_y_pred.cpu().data.numpy())\n",
    "        test_images.extend(data.cpu().data.numpy())\n",
    "        test_label.extend(target.cpu().data.numpy())\n",
    "        adverserial_images.extend((images_adv).cpu().data.numpy())\n",
    "        exp_adv_noise += adv_noise\n",
    "        \n",
    "    #test_loss /= len(data_loader.dataset)\n",
    "    accuracy = 100.00 * correct / len(data_loader.dataset)\n",
    "    #adv_test_loss /= len(data_loader.dataset)\n",
    "    adv_acc = 100.00 * adv_correct / len(data_loader.dataset)\n",
    "    \n",
    "    #average the noise\n",
    "    exp_adv_noise = np.sum(exp_adv_noise)/len(data_loader.dataset)\n",
    "    #visualize\n",
    "    # visualize_adversarial_images(args, 0, adverserial_images, y_preds, y_preds_adv, \n",
    "    #                              test_images, test_label, args.eps_FGSM)\n",
    "    \n",
    "    #sum and average adv_noise_proportion\n",
    "    if args.verbose:\n",
    "        print('\\nTest set: \\nAccuracy: {}/{} ({:.2f}%)\\n'.format(\n",
    "                correct, len(data_loader.dataset), accuracy))\n",
    "        \n",
    "        \n",
    "        print('\\nFGSM -- Adversarial Test set as a classifier: \\nAdv Accuracy: {}/{} ({:.2f}%)\\n'.format(adv_correct, len(data_loader.dataset), adv_acc))\n",
    "        print(f\"\\nNumber of correct classified clean examples(as compared to clean predictions): {correct}/{len(data_loader.dataset)}\")\n",
    "        print(f\"\\nNumber of correct classified adversarial examples(as compared to clean predictions): {adv_correct}/{len(data_loader.dataset)}\")\n",
    "        # print(f\"\\nNumber of attack success: {misclassified}/{len(data_loader.dataset)}\")    \n",
    "    return accuracy, adv_acc, exp_adv_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c7ecded4-ee54-4996-8d27-056e9cce06dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T19:10:11.168246Z",
     "iopub.status.busy": "2023-09-27T19:10:11.167895Z",
     "iopub.status.idle": "2023-09-27T19:10:11.182155Z",
     "shell.execute_reply": "2023-09-27T19:10:11.181498Z",
     "shell.execute_reply.started": "2023-09-27T19:10:11.168208Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_idxs = np.arange(100)\n",
    "data_loader = DataLoader(DatasetSplit(dataset_test, test_idxs), batch_size=args.bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "34820bec-caba-466c-b422-c49d5142233b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T19:10:11.183506Z",
     "iopub.status.busy": "2023-09-27T19:10:11.183141Z",
     "iopub.status.idle": "2023-09-27T19:10:12.709064Z",
     "shell.execute_reply": "2023-09-27T19:10:12.708364Z",
     "shell.execute_reply.started": "2023-09-27T19:10:11.183456Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: \n",
      "Accuracy: 13/100 (13.00%)\n",
      "\n",
      "\n",
      "FGSM -- Adversarial Test set as a classifier: \n",
      "Adv Accuracy: 13/100 (13.00%)\n",
      "\n",
      "\n",
      "Number of correct classified clean examples(as compared to clean predictions): 13/100\n",
      "\n",
      "Number of correct classified adversarial examples(as compared to clean predictions): 13/100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(13.), tensor(13.), 0.06274549971791367)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "test_img(net_glob, dataset_test, test_idxs, args, loss_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d358c8-57ac-403b-9905-825b4da7225b",
   "metadata": {},
   "source": [
    "### Test method 2 with noise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91c9b93-272d-4b34-8711-9f8ff7752ea0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-05T23:39:35.675422Z",
     "iopub.status.busy": "2023-03-05T23:39:35.675005Z",
     "iopub.status.idle": "2023-03-05T23:39:35.679340Z",
     "shell.execute_reply": "2023-03-05T23:39:35.678353Z",
     "shell.execute_reply.started": "2023-03-05T23:39:35.675394Z"
    },
    "tags": []
   },
   "source": [
    "#### evaluate_adversarial_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e920c708-67bb-47fa-9071-f4c42992c48f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T19:10:12.710671Z",
     "iopub.status.busy": "2023-09-27T19:10:12.710302Z",
     "iopub.status.idle": "2023-09-27T19:10:12.722188Z",
     "shell.execute_reply": "2023-09-27T19:10:12.721097Z",
     "shell.execute_reply.started": "2023-09-27T19:10:12.710630Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_adversarial_images(args, images, labels, net_g, criterion, attack_method='Gaussian'):\n",
    "    \n",
    "    correct = 0\n",
    "    if attack_method == 'Gaussian':\n",
    "    # Generate adversarial images using Gaussian perturbation\n",
    "       images_list, images_adv_list = Gaussian_adversarial_images(args, images,\n",
    "                                                                      args.mean, args.sigma, 0, 1)\n",
    "    \n",
    "    elif attack_method == 'FGSM':\n",
    "        adv_correct = 0\n",
    "        images_list, images_adv_list = FGSM(args, net_g, criterion, images, labels,\n",
    "                                                       args.eps_FGSM, args.clip_min, args.clip_max)\n",
    "    elif attack_method == 'FGSM_noise':\n",
    "        adv_correct = 0\n",
    "        images_list, images_adv_list = FGSM(args, net_g, criterion, images, labels,\n",
    "                                                       args.eps_FGSM, args.clip_min, args.clip_max)\n",
    "        \n",
    "        adversarial_images = torch.stack(images_adv_list)\n",
    "        #add noise\n",
    "        (_), images_adv_list = Gaussian_adversarial_images(args, adversarial_images,\n",
    "                                                                      args.mean, args.sigma, args.clip_min, args.clip_max)\n",
    "    else:\n",
    "        exit('Unrecognized attack method')\n",
    "        \n",
    " \n",
    "    images_adv = torch.stack(images_adv_list)    \n",
    "    images_adv = images_adv.to(args.device)\n",
    "    \n",
    "    # print(f'images_adv.shape {images_adv.shape}')\n",
    "    log_probs = net_g(images_adv)\n",
    "    \n",
    "    # print(f'log_probs.shape {log_probs.shape}')\n",
    "    \n",
    "    adv_y_pred = log_probs.data.max(1, keepdim=True)[1]\n",
    "    \n",
    "    # print(f'adv_y_pred.shape {adv_y_pred.shape}')\n",
    "    \n",
    "    # print(f'labels {labels.shape}')\n",
    "    \n",
    "    correct += adv_y_pred.eq(labels.data.view_as(adv_y_pred)).long().cpu().sum()\n",
    "    if attack_method != 'Gaussian':\n",
    "        adv_noise = calculate_expected_perturbation_proportion(args, \n",
    "                                                               images_adv_list, \n",
    "                                                               images_list, \n",
    "                                                               1e-10)\n",
    "        \n",
    "        adv_correct += (adv_y_pred == 10).int().cpu().sum()\n",
    "        #return adversarial attack\n",
    "        return adv_y_pred, correct, adv_correct, adv_noise\n",
    "    #return Gaussian noise\n",
    "    return adv_y_pred, correct\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d4d569-e5e2-49ea-a928-73c0daaec208",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-06T16:09:37.630592Z",
     "iopub.status.busy": "2023-03-06T16:09:37.630225Z",
     "iopub.status.idle": "2023-03-06T16:09:37.638103Z",
     "shell.execute_reply": "2023-03-06T16:09:37.636775Z",
     "shell.execute_reply.started": "2023-03-06T16:09:37.630565Z"
    },
    "tags": []
   },
   "source": [
    "#### test evaluate_adversarial_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "01edf986-8616-473b-a8ca-8f1d514d65af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T19:10:12.723396Z",
     "iopub.status.busy": "2023-09-27T19:10:12.723076Z",
     "iopub.status.idle": "2023-09-27T19:10:12.735567Z",
     "shell.execute_reply": "2023-09-27T19:10:12.734860Z",
     "shell.execute_reply.started": "2023-09-27T19:10:12.723372Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# data_loader = DataLoader(dataset_test, batch_size=args.bs)\n",
    "# criterion = torch.nn.CrossEntropyLoss()\n",
    "# l = len(data_loader)\n",
    "#     # Evaluate the classifier on the normal test set \n",
    "# for idx, (data, target) in enumerate(data_loader):\n",
    "#     with torch.no_grad():\n",
    "#         if args.gpu != -1:\n",
    "#             data, target = data.to(args.device), target.to(args.device) \n",
    "\n",
    "  \n",
    "#     ######################################### Gaussian noise ##################################\n",
    "#         Gaussian_pred, Gaussian_correct = evaluate_adversarial_images(args, data,  \n",
    "#                                                         target,\n",
    "#                                                         net_glob, \n",
    "#                                                         criterion, \n",
    "#                                                         'Gaussian')\n",
    "#         break\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de7ee06-5442-4719-b7e8-bc4a8e482aae",
   "metadata": {},
   "source": [
    "#### test_img_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "033b3a8e-09a4-4c9d-af17-efa4f0419c6c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T19:10:12.737035Z",
     "iopub.status.busy": "2023-09-27T19:10:12.736686Z",
     "iopub.status.idle": "2023-09-27T19:10:12.759135Z",
     "shell.execute_reply": "2023-09-27T19:10:12.758322Z",
     "shell.execute_reply.started": "2023-09-27T19:10:12.736999Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test_img_noise(net_g, datatest, idxs, args, criterion):\n",
    "    net_g.eval()\n",
    "    \n",
    "    # testing\n",
    "    # test_loss = 0\n",
    "    correct = 0\n",
    "    FGSM_correct_rand = 0\n",
    "    \n",
    "    Gaussian_misclassified = 0 #change decision\n",
    "    FGSM_rand_misclassified = 0\n",
    "    \n",
    "    #visualize\n",
    "    FGSM_total_adv_noise  = 0\n",
    "    FGSM_avg_adv_noise = 0.0\n",
    "    #\n",
    "    y_preds = []\n",
    "    Gaussian_pred_list = []\n",
    "    FGSM_pred_rand_list = []\n",
    "    #\n",
    "    test_images = []\n",
    "    test_label = []\n",
    "    #\n",
    "    FGSM_adv_noise = 0\n",
    "    \n",
    "    data_loader = DataLoader(DatasetSplit(datatest, idxs), batch_size=args.bs)\n",
    "    l = len(data_loader)\n",
    "    # Evaluate the classifier on the normal test set \n",
    "    for idx, (data, target) in enumerate(data_loader):\n",
    "        #clean\n",
    "        with torch.no_grad():\n",
    "        \n",
    "            if args.gpu != -1:\n",
    "                data, target = data.to(args.device), target.to(args.device) \n",
    "\n",
    "            log_probs = net_g(data)\n",
    "            # sum up batch loss\n",
    "            # test_loss += F.cross_entropy(log_probs, target, reduction='sum').item()\n",
    "            \n",
    "            # get the index of the max log-probability\n",
    "            y_pred = log_probs.data.max(1, keepdim=True)[1]\n",
    "            correct += y_pred.eq(target.data.view_as(y_pred)).long().cpu().sum()\n",
    "            \n",
    "    ######################################### Gaussian noise ##################################\n",
    "            Gaussian_pred, Gaussian_correct = evaluate_adversarial_images(args, data, \n",
    "                                                            target, \n",
    "                                                            net_g, \n",
    "                                                            criterion, \n",
    "                                                            'Gaussian')\n",
    "\n",
    "    ##############################################FGSM method##################################\n",
    "        \n",
    "        ##############################################FGSM-noise method##################################\n",
    "            \n",
    "        images_list, images_adv_list_noisy = FGSM_noise(args, net_g, criterion, data, \n",
    "                                                  target, args.eps_FGSM,\n",
    "                                                   args.mean, \n",
    "                                                  args.sigma, \n",
    "                                                  args.clip_min, \n",
    "                                                  args.clip_max)\n",
    "        \n",
    "        images_adv_noisy = torch.stack(images_adv_list_noisy) #return a tensor of size (args.bs, 3, 32, 32)\n",
    "        images_adv_noisy = images_adv_noisy.to(args.device)\n",
    "        \n",
    "        adv_noise = calculate_expected_perturbation_proportion(args, \n",
    "                                                               images_list, \n",
    "                                                               images_adv_list_noisy, \n",
    "                                                               1e-10)\n",
    "        with torch.no_grad():\n",
    "            \n",
    "            log_probs = net_g(images_adv_noisy)\n",
    "            # sum up batch loss\n",
    "            # adv_test_loss += F.cross_entropy(log_probs, target, reduction='sum').item()\n",
    "            \n",
    "            # get the index of the max log-probability\n",
    "            FGSM_pred_rand = log_probs.data.max(1, keepdim=True)[1]\n",
    "            FGSM_correct_rand += FGSM_pred_rand.eq(target.data.view_as(FGSM_pred_rand)).long().cpu().sum()\n",
    "        \n",
    "        \n",
    "        ###############################################################################\n",
    "        Gaussian_misclassified += (y_pred != Gaussian_pred).sum().item() #proof of vulnerable\n",
    "        FGSM_rand_misclassified += (y_pred != FGSM_pred_rand).sum().item() #change decision\n",
    "        \n",
    "        ###############################################################################\n",
    "        y_preds.extend(y_pred.cpu().data.numpy())\n",
    "        Gaussian_pred_list.extend(Gaussian_pred.cpu().data.numpy())\n",
    "        FGSM_pred_rand_list.extend(FGSM_pred_rand.cpu().data.numpy())\n",
    "        \n",
    "        ###############################################################################\n",
    "        test_images.extend(data.cpu().data.numpy())\n",
    "        test_label.extend(target.cpu().data.numpy())\n",
    "        \n",
    "        FGSM_total_adv_noise += adv_noise\n",
    "        \n",
    "    #calculates the accuracy of the model on the clean test examples\n",
    "    accuracy = 100.00 * correct / len(data_loader.dataset)\n",
    "    \n",
    "    #calculates the accuracy of the model on the Gaussian adversarial examples\n",
    "    Gaussian_acc = 100.00 * Gaussian_correct / len(data_loader.dataset)\n",
    "        \n",
    "    #FGSM with noise\n",
    "    FGSM_acc_noise = 100.00 * FGSM_correct_rand / len(data_loader.dataset)\n",
    "    \n",
    "    #average the noise\n",
    "    FGSM_avg_adv_noise = np.sum(FGSM_total_adv_noise)/len(data_loader.dataset)\n",
    "    #visualize\n",
    "    # visualize_adversarial_images(args, 0, adverserial_images, y_preds, y_preds_adv, \n",
    "    #                              test_images, test_label, args.eps_FGSM)\n",
    "    \n",
    "    #sum and average adv_noise_proportion\n",
    "    if args.verbose:\n",
    "        print('\\nTest set: \\nAccuracy on benign test examples: {}/{} ({:.2f}%)\\n'.format(\n",
    "                correct, len(data_loader.dataset), accuracy))\n",
    "        \n",
    "        print('\\nTest set: \\nAccuracy on Gaussin noise test examples: {}/{} ({:.2f}%)\\n'.format(\n",
    "                Gaussian_correct, len(data_loader.dataset), Gaussian_acc))\n",
    "        \n",
    "        print('\\nTest accuracy for noisy FGSM: \\nAdv Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
    "                FGSM_acc_noise, len(data_loader.dataset), FGSM_acc_noise))\n",
    "        \n",
    "        # print('\\nNumber of attack success: {}/{}'.format(FGSM_rand_misclassified, len(data_loader.dataset)))\n",
    "        #Jing's evaluation\n",
    "        \n",
    "    return accuracy, Gaussian_acc, FGSM_acc_noise, FGSM_avg_adv_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2d5a049f-697c-4af4-976a-967ebd0e07c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T19:10:12.760596Z",
     "iopub.status.busy": "2023-09-27T19:10:12.760238Z",
     "iopub.status.idle": "2023-09-27T19:10:12.774923Z",
     "shell.execute_reply": "2023-09-27T19:10:12.774174Z",
     "shell.execute_reply.started": "2023-09-27T19:10:12.760560Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_idxs = np.arange(100)\n",
    "data_loader = DataLoader(DatasetSplit(dataset_test, test_idxs), batch_size=args.bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "667f0f64-7bb3-4d78-a723-fbd39b5798a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T19:10:12.776218Z",
     "iopub.status.busy": "2023-09-27T19:10:12.775872Z",
     "iopub.status.idle": "2023-09-27T19:10:12.805995Z",
     "shell.execute_reply": "2023-09-27T19:10:12.804983Z",
     "shell.execute_reply.started": "2023-09-27T19:10:12.776181Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs.size torch.Size([100, 3, 32, 32])\n",
      "targets.size torch.Size([100])\n"
     ]
    }
   ],
   "source": [
    "inputs_n, targets= next(iter(data_loader))\n",
    "\n",
    "print(f'inputs.size {inputs_n.shape}')\n",
    "print(f'targets.size {targets.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6b16efe2-bfbf-4d9c-a034-4d9041ccdf91",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T19:10:12.807221Z",
     "iopub.status.busy": "2023-09-27T19:10:12.806880Z",
     "iopub.status.idle": "2023-09-27T19:10:12.853333Z",
     "shell.execute_reply": "2023-09-27T19:10:12.851645Z",
     "shell.execute_reply.started": "2023-09-27T19:10:12.807188Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.5260e-02, -4.3604e-03,  1.2958e-02, -7.5203e-03, -2.1702e-02,\n",
       "          2.7783e-02,  2.6132e-04,  4.6094e-02,  4.9976e-02, -1.5565e-02],\n",
       "        [-1.4865e-02, -6.2913e-03,  1.2658e-02, -6.0201e-03, -1.7933e-02,\n",
       "          2.6429e-02,  3.2471e-03,  4.9573e-02,  5.5776e-02, -1.1241e-02],\n",
       "        [-1.5609e-02, -6.3284e-03,  1.1169e-02, -6.4800e-03, -1.8456e-02,\n",
       "          2.5335e-02,  2.8501e-03,  4.9339e-02,  5.4343e-02, -1.4442e-02],\n",
       "        [-1.5799e-02, -7.6395e-03,  1.0399e-02, -5.3582e-03, -1.6178e-02,\n",
       "          2.3911e-02,  3.5030e-03,  4.9018e-02,  5.6639e-02, -1.3219e-02],\n",
       "        [-1.4591e-02, -3.2032e-03,  1.2444e-02, -8.7571e-03, -2.1616e-02,\n",
       "          2.7982e-02, -5.1815e-04,  4.5962e-02,  5.0452e-02, -1.7007e-02],\n",
       "        [-1.5536e-02, -3.3680e-03,  1.3195e-02, -9.3046e-03, -2.3043e-02,\n",
       "          2.9431e-02, -6.9858e-04,  4.6389e-02,  4.9353e-02, -1.6242e-02],\n",
       "        [-1.6097e-02, -3.4330e-03,  1.3570e-02, -7.3728e-03, -2.3982e-02,\n",
       "          2.9243e-02, -8.5033e-04,  4.4978e-02,  4.7988e-02, -1.6494e-02],\n",
       "        [-1.4338e-02, -1.8315e-03,  1.2655e-02, -1.0500e-02, -2.4407e-02,\n",
       "          2.9551e-02, -1.3538e-04,  4.5194e-02,  4.8911e-02, -1.7678e-02],\n",
       "        [-1.4791e-02, -6.9038e-03,  1.2858e-02, -6.9553e-03, -1.6541e-02,\n",
       "          2.3737e-02,  2.4775e-03,  5.0154e-02,  5.5643e-02, -1.3494e-02],\n",
       "        [-1.5483e-02, -5.4965e-03,  1.2418e-02, -6.5068e-03, -1.9829e-02,\n",
       "          2.4288e-02,  2.4348e-03,  4.8022e-02,  5.3919e-02, -1.3268e-02],\n",
       "        [-1.4629e-02, -5.8127e-03,  1.0904e-02, -6.6477e-03, -1.8471e-02,\n",
       "          2.5382e-02,  2.7369e-03,  4.7426e-02,  5.2917e-02, -1.5173e-02],\n",
       "        [-1.5935e-02, -5.8211e-03,  1.2677e-02, -8.1723e-03, -2.2739e-02,\n",
       "          2.6606e-02,  1.2330e-03,  4.8613e-02,  5.3310e-02, -1.3767e-02],\n",
       "        [-1.5244e-02, -2.1861e-03,  1.2901e-02, -9.8939e-03, -2.3212e-02,\n",
       "          2.9320e-02, -6.5121e-04,  4.5490e-02,  4.8728e-02, -1.7694e-02],\n",
       "        [-1.4744e-02, -4.8313e-04,  1.3022e-02, -8.8985e-03, -2.3337e-02,\n",
       "          2.9570e-02, -1.1497e-03,  4.2791e-02,  4.7861e-02, -1.9045e-02],\n",
       "        [-1.5449e-02, -4.0765e-03,  1.2415e-02, -7.7966e-03, -2.1854e-02,\n",
       "          2.7807e-02, -9.3301e-05,  4.7331e-02,  5.0937e-02, -1.5666e-02],\n",
       "        [-1.4840e-02, -5.8533e-03,  1.1742e-02, -6.6431e-03, -2.0171e-02,\n",
       "          2.5934e-02,  2.7314e-03,  4.6599e-02,  5.1873e-02, -1.4836e-02],\n",
       "        [-1.5607e-02, -6.6572e-03,  1.2000e-02, -5.8357e-03, -1.7388e-02,\n",
       "          2.5010e-02,  1.8842e-03,  4.8107e-02,  5.3101e-02, -1.5088e-02],\n",
       "        [-1.5124e-02, -4.1344e-03,  1.1985e-02, -9.1254e-03, -2.1526e-02,\n",
       "          2.7703e-02, -9.8990e-05,  4.6940e-02,  5.0824e-02, -1.5734e-02],\n",
       "        [-1.4742e-02, -5.7261e-03,  1.2702e-02, -6.6297e-03, -1.9433e-02,\n",
       "          2.5759e-02,  3.0919e-03,  4.9169e-02,  5.4558e-02, -1.2557e-02],\n",
       "        [-1.4568e-02, -2.8686e-03,  1.3923e-02, -9.8185e-03, -2.2761e-02,\n",
       "          2.9532e-02, -7.3486e-04,  4.5406e-02,  4.9058e-02, -1.6342e-02],\n",
       "        [-1.5356e-02, -4.3927e-03,  1.2388e-02, -8.0829e-03, -2.1510e-02,\n",
       "          2.7377e-02,  5.0294e-04,  4.7044e-02,  5.1365e-02, -1.6083e-02],\n",
       "        [-1.5022e-02, -1.1135e-02,  1.1464e-02, -2.8165e-03, -1.2608e-02,\n",
       "          2.0490e-02,  5.7989e-03,  5.2254e-02,  6.1673e-02, -8.8229e-03],\n",
       "        [-1.5289e-02, -9.5552e-04,  1.1121e-02, -9.6196e-03, -2.4781e-02,\n",
       "          2.9818e-02, -8.9462e-04,  4.3802e-02,  4.6185e-02, -1.9467e-02],\n",
       "        [-1.5819e-02, -2.4000e-03,  1.2464e-02, -8.7657e-03, -2.3069e-02,\n",
       "          2.8205e-02, -1.8132e-03,  4.5697e-02,  4.8119e-02, -1.8796e-02],\n",
       "        [-1.4513e-02, -5.5082e-03,  1.3837e-02, -7.9411e-03, -2.0063e-02,\n",
       "          2.6864e-02,  1.6473e-03,  4.8845e-02,  5.2712e-02, -1.3489e-02],\n",
       "        [-1.3898e-02, -3.2672e-03,  1.2526e-02, -8.1798e-03, -2.2257e-02,\n",
       "          2.7965e-02,  8.0129e-04,  4.6077e-02,  5.0092e-02, -1.4771e-02],\n",
       "        [-1.4751e-02, -2.3451e-03,  1.2945e-02, -1.0543e-02, -2.4033e-02,\n",
       "          2.9427e-02, -1.5063e-03,  4.4952e-02,  4.8102e-02, -1.7795e-02],\n",
       "        [-1.4760e-02, -5.9957e-03,  1.2186e-02, -7.5382e-03, -2.1167e-02,\n",
       "          2.6483e-02,  2.4305e-03,  4.9637e-02,  5.4031e-02, -1.3638e-02],\n",
       "        [-1.4837e-02, -4.7451e-03,  1.2316e-02, -8.1413e-03, -2.1829e-02,\n",
       "          2.6904e-02,  6.1827e-05,  4.7482e-02,  5.1511e-02, -1.5390e-02],\n",
       "        [-1.4583e-02, -1.3752e-03,  1.4563e-02, -9.8383e-03, -2.4960e-02,\n",
       "          3.0444e-02, -1.6854e-03,  4.5735e-02,  4.7813e-02, -1.8517e-02],\n",
       "        [-1.5078e-02, -8.2440e-04,  1.4048e-02, -1.1313e-02, -2.7149e-02,\n",
       "          3.1807e-02, -2.8831e-03,  4.4262e-02,  4.5241e-02, -1.9575e-02],\n",
       "        [-1.5071e-02, -4.6812e-03,  1.3434e-02, -8.2784e-03, -1.9454e-02,\n",
       "          2.7662e-02, -3.3125e-04,  4.8901e-02,  5.3260e-02, -1.5402e-02],\n",
       "        [-1.4460e-02, -4.2442e-03,  1.2371e-02, -8.4139e-03, -1.9879e-02,\n",
       "          2.6298e-02,  1.0388e-03,  4.7118e-02,  5.2384e-02, -1.5478e-02],\n",
       "        [-1.5089e-02, -3.6957e-03,  1.2548e-02, -8.1123e-03, -2.1144e-02,\n",
       "          2.5559e-02,  2.5341e-04,  4.7143e-02,  5.0446e-02, -1.6373e-02],\n",
       "        [-1.5927e-02, -3.4901e-03,  1.1276e-02, -7.9076e-03, -2.3747e-02,\n",
       "          2.7929e-02,  1.0918e-03,  4.7519e-02,  5.1132e-02, -1.6946e-02],\n",
       "        [-1.5287e-02, -2.1927e-03,  1.2489e-02, -8.6638e-03, -2.2524e-02,\n",
       "          2.8342e-02, -2.3273e-04,  4.4800e-02,  4.8585e-02, -1.7879e-02],\n",
       "        [-1.4755e-02, -4.5093e-03,  1.3174e-02, -8.5837e-03, -2.0924e-02,\n",
       "          2.8120e-02,  2.6660e-04,  4.8684e-02,  5.2898e-02, -1.4508e-02],\n",
       "        [-1.5643e-02, -8.9525e-03,  1.1716e-02, -4.4833e-03, -1.6821e-02,\n",
       "          2.2516e-02,  3.8390e-03,  4.9962e-02,  5.7730e-02, -1.2255e-02],\n",
       "        [-1.5916e-02, -6.2704e-03,  1.1480e-02, -6.3341e-03, -1.9072e-02,\n",
       "          2.4168e-02,  2.3796e-03,  4.8503e-02,  5.3541e-02, -1.4141e-02],\n",
       "        [-1.4552e-02, -5.4819e-03,  1.1936e-02, -7.1189e-03, -1.8840e-02,\n",
       "          2.5868e-02,  1.6949e-03,  4.7708e-02,  5.3573e-02, -1.5904e-02],\n",
       "        [-1.5529e-02, -6.3328e-03,  1.1149e-02, -6.9711e-03, -2.0324e-02,\n",
       "          2.4846e-02,  2.1940e-03,  4.7476e-02,  5.3147e-02, -1.4881e-02],\n",
       "        [-1.4873e-02,  6.9334e-04,  1.3604e-02, -1.1679e-02, -2.6946e-02,\n",
       "          3.2389e-02, -3.3507e-03,  4.3507e-02,  4.4620e-02, -2.0630e-02],\n",
       "        [-1.5579e-02, -3.5428e-03,  1.1964e-02, -8.6402e-03, -2.3253e-02,\n",
       "          2.8430e-02, -5.4282e-04,  4.6345e-02,  4.9171e-02, -1.7300e-02],\n",
       "        [-1.4314e-02, -2.3770e-03,  1.3086e-02, -1.0539e-02, -2.4567e-02,\n",
       "          2.9708e-02, -1.8862e-03,  4.4697e-02,  4.7571e-02, -1.7295e-02],\n",
       "        [-1.6384e-02, -4.8991e-03,  1.0281e-02, -4.2185e-03, -1.9069e-02,\n",
       "          2.5435e-02,  2.2689e-03,  4.8759e-02,  5.2675e-02, -1.6845e-02],\n",
       "        [-1.7110e-02, -7.3794e-03,  1.0944e-02, -6.4027e-03, -1.9780e-02,\n",
       "          2.6052e-02,  2.7336e-03,  4.9044e-02,  5.5380e-02, -1.2470e-02],\n",
       "        [-1.3724e-02, -2.4401e-03,  1.4199e-02, -9.9447e-03, -2.2916e-02,\n",
       "          2.9853e-02, -9.5985e-04,  4.5351e-02,  4.8196e-02, -1.6225e-02],\n",
       "        [-1.5850e-02, -2.9317e-03,  1.2004e-02, -9.2207e-03, -2.2761e-02,\n",
       "          2.6574e-02,  2.0185e-05,  4.4501e-02,  4.8853e-02, -1.7469e-02],\n",
       "        [-1.3743e-02, -3.2094e-03,  1.2900e-02, -8.9780e-03, -2.2517e-02,\n",
       "          2.8888e-02, -3.5755e-04,  4.7776e-02,  5.1088e-02, -1.6770e-02],\n",
       "        [-1.3761e-02, -2.1178e-03,  1.4276e-02, -9.7255e-03, -2.4831e-02,\n",
       "          3.0777e-02, -1.1247e-03,  4.7220e-02,  4.9454e-02, -1.7385e-02],\n",
       "        [-1.5686e-02, -5.3385e-03,  9.8027e-03, -6.1378e-03, -2.0452e-02,\n",
       "          2.5327e-02,  2.3935e-03,  4.7215e-02,  5.2625e-02, -1.6154e-02],\n",
       "        [-1.5494e-02, -3.5853e-03,  1.2591e-02, -9.2604e-03, -2.2066e-02,\n",
       "          2.8746e-02,  6.2993e-04,  4.6889e-02,  5.0413e-02, -1.6557e-02],\n",
       "        [-1.4546e-02, -1.6691e-03,  1.3503e-02, -1.0154e-02, -2.4298e-02,\n",
       "          2.9667e-02, -1.3452e-03,  4.4181e-02,  4.7391e-02, -1.8005e-02],\n",
       "        [-1.6165e-02, -3.7684e-03,  1.4096e-02, -9.2540e-03, -2.3871e-02,\n",
       "          2.9270e-02, -4.4471e-04,  4.6572e-02,  4.9788e-02, -1.5780e-02],\n",
       "        [-1.5720e-02, -6.2276e-03,  1.1624e-02, -5.8412e-03, -1.8609e-02,\n",
       "          2.5273e-02,  3.8461e-03,  4.8593e-02,  5.5517e-02, -1.2791e-02],\n",
       "        [-1.4795e-02, -4.7512e-03,  1.1627e-02, -8.2483e-03, -1.9404e-02,\n",
       "          2.6265e-02,  2.0710e-03,  4.8276e-02,  5.3642e-02, -1.4909e-02],\n",
       "        [-1.5369e-02, -5.5537e-03,  1.2086e-02, -6.4663e-03, -1.8883e-02,\n",
       "          2.5807e-02,  8.8488e-04,  4.7623e-02,  5.2689e-02, -1.6106e-02],\n",
       "        [-1.4545e-02, -1.6453e-04,  1.3592e-02, -1.0719e-02, -2.5818e-02,\n",
       "          3.0803e-02, -2.2586e-03,  4.2930e-02,  4.5071e-02, -2.0588e-02],\n",
       "        [-1.4582e-02, -6.6349e-03,  1.1998e-02, -6.7586e-03, -1.8961e-02,\n",
       "          2.4771e-02,  2.5343e-03,  4.9197e-02,  5.4744e-02, -1.4139e-02],\n",
       "        [-1.4742e-02, -4.4326e-03,  1.2141e-02, -9.0219e-03, -2.0583e-02,\n",
       "          2.6812e-02,  5.2060e-04,  4.6512e-02,  5.1167e-02, -1.5334e-02],\n",
       "        [-1.4852e-02, -5.4416e-03,  1.3302e-02, -7.8770e-03, -1.9930e-02,\n",
       "          2.5777e-02,  1.3896e-03,  4.8600e-02,  5.3580e-02, -1.4591e-02],\n",
       "        [-1.4250e-02, -2.4467e-03,  1.4422e-02, -1.0576e-02, -2.4046e-02,\n",
       "          2.9586e-02, -1.8000e-03,  4.4897e-02,  4.7578e-02, -1.7520e-02],\n",
       "        [-1.4193e-02,  6.8447e-05,  1.3663e-02, -1.0851e-02, -2.5630e-02,\n",
       "          3.1406e-02, -2.7224e-03,  4.2761e-02,  4.3470e-02, -1.9860e-02],\n",
       "        [-1.3740e-02, -5.9999e-03,  1.2163e-02, -6.6091e-03, -2.0552e-02,\n",
       "          2.7525e-02,  2.5392e-03,  4.9952e-02,  5.5392e-02, -1.4066e-02],\n",
       "        [-1.5433e-02, -3.8225e-03,  1.2927e-02, -9.3881e-03, -2.3408e-02,\n",
       "          2.7752e-02, -9.8534e-05,  4.6647e-02,  5.0450e-02, -1.5915e-02],\n",
       "        [-1.4542e-02, -2.8242e-03,  1.2323e-02, -9.3849e-03, -2.4157e-02,\n",
       "          2.9352e-02, -8.6952e-04,  4.5232e-02,  4.8366e-02, -1.8101e-02],\n",
       "        [-1.5310e-02, -3.5357e-03,  1.1910e-02, -8.4058e-03, -2.1952e-02,\n",
       "          2.7618e-02,  4.2481e-04,  4.6970e-02,  5.0581e-02, -1.5733e-02],\n",
       "        [-1.5377e-02, -7.4085e-03,  9.9058e-03, -3.6154e-03, -1.6203e-02,\n",
       "          2.3024e-02,  4.7306e-03,  4.8768e-02,  5.4597e-02, -1.3376e-02],\n",
       "        [-1.3529e-02, -9.1786e-04,  1.3344e-02, -1.0361e-02, -2.5358e-02,\n",
       "          3.0314e-02, -2.6042e-03,  4.4012e-02,  4.5254e-02, -1.8095e-02],\n",
       "        [-1.5230e-02, -4.8656e-03,  1.2848e-02, -6.8601e-03, -2.1313e-02,\n",
       "          2.7471e-02,  1.1475e-03,  4.8043e-02,  5.1264e-02, -1.4448e-02],\n",
       "        [-1.4692e-02, -7.4153e-03,  1.2294e-02, -7.8877e-03, -1.7978e-02,\n",
       "          2.4581e-02,  2.4211e-03,  5.0242e-02,  5.6339e-02, -1.1932e-02],\n",
       "        [-1.4904e-02, -2.7730e-03,  1.2179e-02, -1.0319e-02, -2.2726e-02,\n",
       "          2.9367e-02, -1.8402e-03,  4.5843e-02,  4.8594e-02, -1.9034e-02],\n",
       "        [-1.5574e-02, -7.8301e-03,  1.2067e-02, -7.2334e-03, -1.7169e-02,\n",
       "          2.4391e-02,  3.4487e-03,  5.0420e-02,  5.6719e-02, -1.1925e-02],\n",
       "        [-1.4812e-02, -4.7913e-03,  1.1418e-02, -7.6832e-03, -1.9023e-02,\n",
       "          2.7094e-02,  1.9047e-03,  4.7497e-02,  5.3161e-02, -1.5884e-02],\n",
       "        [-1.4995e-02, -5.1709e-03,  1.1860e-02, -6.5953e-03, -2.0796e-02,\n",
       "          2.6770e-02,  2.6007e-03,  4.9108e-02,  5.4047e-02, -1.3686e-02],\n",
       "        [-1.3740e-02, -3.9336e-03,  1.3273e-02, -8.4103e-03, -2.2079e-02,\n",
       "          2.8728e-02,  7.6438e-04,  4.7350e-02,  5.0207e-02, -1.5492e-02],\n",
       "        [-1.6313e-02, -5.8445e-03,  1.1326e-02, -6.5255e-03, -2.0743e-02,\n",
       "          2.4812e-02,  2.2720e-03,  4.7763e-02,  5.2327e-02, -1.5590e-02],\n",
       "        [-1.4383e-02, -2.9442e-03,  1.2309e-02, -9.1130e-03, -2.1288e-02,\n",
       "          2.8910e-02, -6.6056e-04,  4.5550e-02,  5.0225e-02, -1.7014e-02],\n",
       "        [-1.4053e-02, -7.8952e-04,  1.3646e-02, -1.0464e-02, -2.5395e-02,\n",
       "          3.0426e-02, -1.9189e-03,  4.3852e-02,  4.6516e-02, -1.8729e-02],\n",
       "        [-1.5860e-02, -1.1352e-02,  1.1226e-02, -4.9968e-03, -1.3823e-02,\n",
       "          2.0724e-02,  5.1291e-03,  5.3178e-02,  6.0921e-02, -9.5434e-03],\n",
       "        [-1.4857e-02, -7.5898e-03,  1.1953e-02, -6.0312e-03, -1.7049e-02,\n",
       "          2.4173e-02,  4.2362e-03,  5.0409e-02,  5.6789e-02, -1.2501e-02],\n",
       "        [-1.5120e-02,  2.3243e-04,  1.2822e-02, -1.0253e-02, -2.5803e-02,\n",
       "          3.1300e-02, -2.7197e-03,  4.2133e-02,  4.4734e-02, -1.9109e-02],\n",
       "        [-1.4244e-02, -2.5658e-03,  1.3030e-02, -8.5938e-03, -2.4290e-02,\n",
       "          2.9798e-02,  2.5412e-04,  4.5797e-02,  4.9228e-02, -1.6365e-02],\n",
       "        [-1.4978e-02, -9.8806e-03,  1.1854e-02, -5.4888e-03, -1.4978e-02,\n",
       "          2.2982e-02,  4.3397e-03,  5.2303e-02,  5.9363e-02, -1.0375e-02],\n",
       "        [-1.5678e-02, -9.4301e-03,  1.1563e-02, -5.5353e-03, -1.4919e-02,\n",
       "          2.2022e-02,  4.5273e-03,  5.1519e-02,  5.9641e-02, -1.0059e-02],\n",
       "        [-1.5321e-02, -3.9219e-03,  1.1732e-02, -7.7388e-03, -2.2172e-02,\n",
       "          2.7412e-02,  9.9566e-04,  4.6447e-02,  5.0387e-02, -1.7245e-02],\n",
       "        [-1.5307e-02, -3.0047e-03,  1.0737e-02, -6.0748e-03, -2.0489e-02,\n",
       "          2.7212e-02,  1.1533e-03,  4.5177e-02,  4.9715e-02, -1.7604e-02],\n",
       "        [-1.5177e-02, -9.0142e-03,  1.1773e-02, -5.0982e-03, -1.4687e-02,\n",
       "          2.2354e-02,  4.7429e-03,  5.1890e-02,  5.8584e-02, -1.0771e-02],\n",
       "        [-1.4984e-02, -7.8655e-03,  1.3197e-02, -6.3413e-03, -1.7207e-02,\n",
       "          2.4888e-02,  3.2881e-03,  5.1080e-02,  5.7901e-02, -1.1393e-02],\n",
       "        [-1.5105e-02, -4.2010e-03,  1.1474e-02, -7.6153e-03, -2.0478e-02,\n",
       "          2.7336e-02,  8.3271e-04,  4.8337e-02,  5.2532e-02, -1.4726e-02],\n",
       "        [-1.5368e-02, -5.2109e-03,  1.1212e-02, -7.0619e-03, -2.0323e-02,\n",
       "          2.7611e-02,  2.3512e-03,  4.8409e-02,  5.3009e-02, -1.4507e-02],\n",
       "        [-1.4318e-02, -1.2654e-03,  1.3984e-02, -1.0275e-02, -2.4443e-02,\n",
       "          3.0324e-02, -1.8225e-03,  4.5529e-02,  4.7691e-02, -1.8587e-02],\n",
       "        [-1.5232e-02, -9.4976e-03,  1.0652e-02, -4.5372e-03, -1.4547e-02,\n",
       "          2.3451e-02,  5.1568e-03,  5.1777e-02,  5.9728e-02, -1.0281e-02],\n",
       "        [-1.4049e-02, -3.8165e-03,  1.2821e-02, -8.0886e-03, -2.2433e-02,\n",
       "          2.7781e-02,  6.2069e-04,  4.7223e-02,  5.0347e-02, -1.6151e-02],\n",
       "        [-1.4316e-02, -1.3939e-03,  1.2657e-02, -1.0753e-02, -2.4236e-02,\n",
       "          3.0796e-02, -1.6257e-03,  4.4618e-02,  4.7334e-02, -1.8169e-02],\n",
       "        [-1.4766e-02, -4.6322e-03,  1.3438e-02, -7.9809e-03, -2.0319e-02,\n",
       "          2.6392e-02,  7.9944e-05,  4.7245e-02,  5.0804e-02, -1.6218e-02],\n",
       "        [-1.4402e-02, -3.6837e-03,  1.3582e-02, -8.6908e-03, -2.2211e-02,\n",
       "          2.8658e-02, -4.3899e-04,  4.6946e-02,  4.9944e-02, -1.6707e-02],\n",
       "        [-1.4725e-02, -5.2886e-03,  1.1105e-02, -7.9895e-03, -1.8399e-02,\n",
       "          2.5465e-02,  2.2763e-03,  4.8031e-02,  5.3594e-02, -1.4935e-02],\n",
       "        [-1.5460e-02, -1.2510e-02,  1.0907e-02, -2.9790e-03, -1.3044e-02,\n",
       "          1.9551e-02,  4.9833e-03,  5.2742e-02,  6.0351e-02, -9.2898e-03],\n",
       "        [-1.4329e-02, -7.7861e-03,  1.3251e-02, -6.9223e-03, -1.8838e-02,\n",
       "          2.5463e-02,  2.1727e-03,  5.1079e-02,  5.6049e-02, -1.2843e-02]],\n",
       "       device='cuda:0', grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net_glob(inputs_n) #clear output after being run successfully"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc93accd-abd4-40ff-ac9d-1f1cf839f778",
   "metadata": {},
   "source": [
    "# NOTE:  Test only the first 100 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "074d9bcf-f20f-428c-987a-3dc0635073d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T19:10:12.854608Z",
     "iopub.status.busy": "2023-09-27T19:10:12.854249Z",
     "iopub.status.idle": "2023-09-27T19:10:12.965468Z",
     "shell.execute_reply": "2023-09-27T19:10:12.964811Z",
     "shell.execute_reply.started": "2023-09-27T19:10:12.854570Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: \n",
      "Accuracy on benign test examples: 13/100 (13.00%)\n",
      "\n",
      "\n",
      "Test set: \n",
      "Accuracy on Gaussin noise test examples: 13/100 (13.00%)\n",
      "\n",
      "\n",
      "Test accuracy for noisy FGSM: \n",
      "Adv Accuracy: 13.0/100 (13.00%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "test_idxs = np.arange(100)\n",
    "accuracy, Gaussian_acc, FGSM_acc_nois, exp_adv_noise = test_img_noise(net_glob, \n",
    "    dataset_test, test_idxs, args, loss_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b048c52d-a449-44c5-b241-31e18b7b4bcc",
   "metadata": {},
   "source": [
    "## generate_adversarial_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d92350a4-c370-4acd-bbbc-206acf2d5f0f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T19:10:12.966976Z",
     "iopub.status.busy": "2023-09-27T19:10:12.966603Z",
     "iopub.status.idle": "2023-09-27T19:10:12.974504Z",
     "shell.execute_reply": "2023-09-27T19:10:12.973380Z",
     "shell.execute_reply.started": "2023-09-27T19:10:12.966936Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def generate_adversarial_images(args, images, labels, net_glob, criterion):\n",
    "    \n",
    "    # Generate adversarial images using Gaussian perturbation\n",
    "    images_list, adversarial_images = Gaussian_adversarial_images(args, images,\n",
    "                                                                  args.mean, args.sigma, \n",
    "                                                                  args.clip_min,\n",
    "                                                                  args.clip_max)\n",
    "    \n",
    "\n",
    "    adversarial_images = torch.stack(adversarial_images)\n",
    "    # print(f'Gaussian noise adversarial_images size: {adversarial_images.shape[0]}')\n",
    "    \n",
    "    # Generate adversarial images using Projected Gradient Descent (PGD)\n",
    "    adversary = LinfPGDAttack(net_glob, eps=args.eps, nb_iter=args.nb_iter, \n",
    "                                            eps_iter=args.eps_iter,\n",
    "                                            clip_min=args.clip_min,\n",
    "                                            clip_max=args.clip_max)\n",
    "    \n",
    "    adversarial_images_PGD = adversary.perturb(images, labels)\n",
    "\n",
    "    adversarial_images = torch.cat([adversarial_images, adversarial_images_PGD], dim=0)\n",
    "    # print(f'PGD noise adversarial_images size: {adversarial_images_PGD.shape[0]}')\n",
    "    \n",
    "    # print(f'the augmented training set size: {adversarial_images.shape[0]}')\n",
    "\n",
    "    return adversarial_images\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ba3ca9-ce5a-4efa-8c85-68265c4ac78c",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f2b8e3-2692-48e2-a30a-be011be1f012",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-24T15:26:30.076879Z",
     "iopub.status.busy": "2023-07-24T15:26:30.076458Z",
     "iopub.status.idle": "2023-07-24T15:26:30.083427Z",
     "shell.execute_reply": "2023-07-24T15:26:30.082500Z",
     "shell.execute_reply.started": "2023-07-24T15:26:30.076842Z"
    },
    "tags": []
   },
   "source": [
    "### save_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "78cceb61-93e4-498c-bf0f-f98ea5085f93",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T19:10:12.975742Z",
     "iopub.status.busy": "2023-09-27T19:10:12.975388Z",
     "iopub.status.idle": "2023-09-27T19:10:12.989115Z",
     "shell.execute_reply": "2023-09-27T19:10:12.988343Z",
     "shell.execute_reply.started": "2023-09-27T19:10:12.975706Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_model(start_time, args, net_glob, idxs_users):\n",
    "    try:\n",
    "        now = datetime.now()\n",
    "        print(\"Total time for the training: {} seconds ---\".format(now - start_time))\n",
    "        now = start_time.strftime(\"%Y-%m-%dT%H-%M-%S\")\n",
    "\n",
    "        file = f'{args.fed}_{args.eps_FGSM}_{args.dataset}_{args.model}_{args.rounds}_{args.local_ep}_nParties_{len(idxs_users)}_{args.sampling}__{args.classwise}_{args.alpha}_model'\n",
    "        model_name = '{}_{}.pt'.format(file, now)\n",
    "        filepath = './save/'\n",
    "        \n",
    "        if not os.path.exists(filepath):\n",
    "            os.makedirs(filepath)\n",
    "\n",
    "        f_model = os.path.join(filepath, model_name)\n",
    "        torch.save(net_glob.state_dict(), f_model)\n",
    "        \n",
    "        print('The final model saved to: ', f_model)\n",
    "        \n",
    "        return f_model\n",
    "    except Exception as e:\n",
    "        print(f'Error saving model: {e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48741f0b-4cb0-4fd1-82ec-3c9e47722b97",
   "metadata": {},
   "source": [
    "### save_model_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "38304b6d-9f78-47a5-b42f-144a2be55be0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T19:10:12.990448Z",
     "iopub.status.busy": "2023-09-27T19:10:12.990102Z",
     "iopub.status.idle": "2023-09-27T19:10:13.004460Z",
     "shell.execute_reply": "2023-09-27T19:10:13.003741Z",
     "shell.execute_reply.started": "2023-09-27T19:10:12.990411Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_model_performance(args, start_time, rounds_test_accuracy,\n",
    "                           rounds_train_loss, \n",
    "                           rounds_adv_test_accuracy, \n",
    "                           rounds_adv_test_accuracy_2,\n",
    "                           idxs_users):\n",
    "    try:\n",
    "        output = {}\n",
    "        output['rounds_test_accuracy'] = rounds_test_accuracy\n",
    "        output['rounds_train_loss'] = rounds_train_loss\n",
    "        output['rounds_adv_test_accuracy'] = rounds_adv_test_accuracy\n",
    "        output['rounds_adv_test_accuracy_2'] = rounds_adv_test_accuracy_2\n",
    "\n",
    "        temp='./save/'\n",
    "        \n",
    "\n",
    "        filename = f'{args.fed}_{args.eps_FGSM}_{args.dataset}_{args.model}_${args.rounds}_{args.local_ep}_nParties_{len(idxs_users)}_{args.sampling}_{args.classwise}_{args.alpha}'\n",
    "        filename = '{}_{}.out'.format(filename, start_time.strftime(\"%Y-%m-%dT%H-%M-%S\"))\n",
    "        filepath = os.path.join(temp, filename)\n",
    "        print('filepath ', filepath)\n",
    "        outfile = open(filepath,'wb')\n",
    "        pickle.dump(output, outfile)\n",
    "\n",
    "        print('The output file saved to: ', filepath)\n",
    "    except Exception as e:\n",
    "            print(f'Error saving model performance: {e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b13b89c-ffe2-44d2-8aae-eac542ef6016",
   "metadata": {},
   "source": [
    "### read_model_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "63467095-4162-441d-9521-99c9b3418a6c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T19:10:13.006099Z",
     "iopub.status.busy": "2023-09-27T19:10:13.005733Z",
     "iopub.status.idle": "2023-09-27T19:10:13.020000Z",
     "shell.execute_reply": "2023-09-27T19:10:13.019310Z",
     "shell.execute_reply.started": "2023-09-27T19:10:13.006063Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_model_performance(args, temp, idxs_users):\n",
    "    try:\n",
    "        temp='./save/'\n",
    "        filename = f'{args.fed}_{args.eps_FGSM}_{args.dataset}_{args.model}_{args.local_ep}_nParties_{idxs_users}_{args.sampling}_{args.classwise}_{args.alpha}_output.out'\n",
    "        filepath = os.path.join(temp, filename)\n",
    "        print('filepath ', filepath)\n",
    "        \n",
    "        output = pickle.load(open(filepath, \"rb\"))\n",
    "        \n",
    "        rounds_test_accuracy = output['rounds_test_accuracy']\n",
    "        rounds_train_loss = output['rounds_train_loss']\n",
    "        rounds_adv_test_accuracy = output['rounds_adv_test_accuracy'] \n",
    "        rounds_adv_test_accuracy_2 = output['rounds_adv_test_accuracy_2']\n",
    "        \n",
    "        print(len(rounds_test_accuracy))\n",
    "        print(len(rounds_adv_test_accuracy_2))\n",
    "        print(len(rounds_train_loss))\n",
    "        ################### training loss ######################\n",
    "#         label = args.fed\n",
    "#         plt.xlabel(\"Global Iterations\")\n",
    "#         plt.ylabel(f\"Train loss\")\n",
    "#         # plt.set_yscale('log')\n",
    "#         plt.title(f\"Centralized AT - Dataset: {args.dataset} - Model: {args.model} - Soft labelling\" )\n",
    "#         plt.plot(rounds_train_loss, label='soft label')\n",
    "        \n",
    "#         plt.legend(loc=\"center right\")\n",
    "#         plt.show()\n",
    "#         plt.close()\n",
    "        ###################################################\n",
    "        label = args.fed\n",
    "        plt.xlabel(\"Global Iterations\")\n",
    "        plt.ylabel(f\"Test acc\")\n",
    "        # plt.set_yscale('log')\n",
    "        plt.title(f\"Centralized AT - Dataset: {args.dataset} - Model: {args.model} - Soft labelling\" )\n",
    "        plt.plot(rounds_test_accuracy, label='clean acc')\n",
    "        plt.plot(rounds_adv_test_accuracy, label='additional class acc')\n",
    "        plt.plot(rounds_adv_test_accuracy_2, label='robust acc')\n",
    "        \n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "        \n",
    "    except Exception as e:\n",
    "            print(f'Error loading model performance: {e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56271429-4e6f-4db8-bdc3-1e36583f3622",
   "metadata": {},
   "source": [
    "### parse_output_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "33de07a0-46bc-4014-84a5-52e184c82573",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T19:10:13.021397Z",
     "iopub.status.busy": "2023-09-27T19:10:13.021048Z",
     "iopub.status.idle": "2023-09-27T19:10:13.035317Z",
     "shell.execute_reply": "2023-09-27T19:10:13.034640Z",
     "shell.execute_reply.started": "2023-09-27T19:10:13.021360Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def parse_output_log(args, file_name, save_file_path):\n",
    "    train_loss = []\n",
    "    test_accuracy = []\n",
    "    adv_accuracy = []\n",
    "    \n",
    "    for line in open(file_name, 'r'):\n",
    "        # print(line) \n",
    "        # Search for average train loss over parties\n",
    "        search_avg_train_loss = re.search(r'Average train loss over \\[(.*)\\] parties: ([\\d\\.]+)', line, re.M|re.I)\n",
    "        if search_avg_train_loss:\n",
    "            val = float(search_avg_train_loss.group(2))\n",
    "            train_loss.append(val/args.num_users)\n",
    "        \n",
    "        # # search for test accuracy\n",
    "        # search_test_accu = re.search(r'Number of correct classified clean examples\\(as compared to clean predictions\\): (\\d+)/\\d+', line, re.M|re.I)\n",
    "        # if search_test_accu:\n",
    "        #     val = float(search_test_accu.group(1))\n",
    "        #     # print(val)\n",
    "        #     test_accuracy.append(val/100)\n",
    "        #     # if(len(test_accuracy) == 5):\n",
    "        #     #     break\n",
    "        # # search for adversarial accuracy\n",
    "        # search_adv_accu = re.search(r'Adv Accuracy: \\d+/\\d+ \\((\\d+\\.\\d+)%\\)', line, re.M|re.I)\n",
    "        # if search_adv_accu:\n",
    "        #     val = float(search_adv_accu.group(1))\n",
    "        #     if val > 1.0:\n",
    "        #         adv_accuracy.append(float(search_adv_accu.group(1)))\n",
    "        \n",
    "    print(f'train_loss {len(train_loss)}')\n",
    "    # print(f'test_accuracy {len(test_accuracy)}')\n",
    "    # print(f'adv_accuracy {len(adv_accuracy)}')\n",
    "    \n",
    "    # plot train loss\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.xlabel(\"Global Iterations\")\n",
    "    plt.ylabel(f\"Train loss\")\n",
    "\n",
    "    filename = f'{args.fed}_{args.adv_eps}_{args.dataset}_{args.model}_{args.local_ep}_nParties_{args.num_users}_{args.sampling}_{args.classwise}_{args.alpha}'\n",
    "\n",
    "    plt.title(f\"AT - Dataset: {args.dataset} - Model: {args.model} - N = {args.num_users} - Sampling: {args.sampling}\" )\n",
    "    plt.plot(train_loss, label='train loss')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    filepath_1 = save_file_path + '/' + f'{filename}_train_loss.png'\n",
    "    print(filepath_1)\n",
    "    plt.savefig(filepath_1)\n",
    "    # plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    # # plot test accuracy\n",
    "    # plt.xlabel(\"Global Iterations\")\n",
    "    # plt.ylabel(f\"Test acc\")\n",
    "    # # plt.set_yscale('log')\n",
    "    # plt.title(f\"AT - Dataset: {args.dataset} - Model: {args.model} - N = {args.num_users} - Sampling: {args.sampling}\" )\n",
    "    # plt.plot(test_accuracy, label='clean acc') #scale: 0.8\n",
    "    # plt.plot(adv_accuracy, label='robust acc') #percentage\n",
    "\n",
    "    # plt.legend(loc=\"lower right\")\n",
    "    # # plt.show()\n",
    "    # print(filepath_2)\n",
    "    # filepath_2 = save_file_path + '/' + f'{filename}_robust_acc.png'\n",
    "    # plt.savefig(filepath_2)\n",
    "    # plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5fcd5d7-8056-4455-bc45-839726c39052",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "### Run parse_output_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4bbd51d7-d2e0-4861-b518-465690c28d91",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T19:10:13.036810Z",
     "iopub.status.busy": "2023-09-27T19:10:13.036445Z",
     "iopub.status.idle": "2023-09-27T19:10:13.047654Z",
     "shell.execute_reply": "2023-09-27T19:10:13.046938Z",
     "shell.execute_reply.started": "2023-09-27T19:10:13.036773Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# file_name = 'AT_out_fedavg_0.031_cifar_customized_resnet18_100_3_nParties_twoclassnoniid_10_noshare'\n",
    "# parse_output_log(args, file_name, './save/AT/Figures')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2c7629-f489-412a-b89a-a448d27d8c64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b6d0a277-7654-4e20-8f1b-c9fbfa15d804",
   "metadata": {},
   "source": [
    "# Update local weights using adversarial examples and soft labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0df16a37-9582-4c02-a5ab-ba0878722b46",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T19:10:13.049009Z",
     "iopub.status.busy": "2023-09-27T19:10:13.048659Z",
     "iopub.status.idle": "2023-09-27T19:10:13.059951Z",
     "shell.execute_reply": "2023-09-27T19:10:13.059252Z",
     "shell.execute_reply.started": "2023-09-27T19:10:13.048971Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def adjust_learning_rate(args, optimizer, epoch):\n",
    "        lr = args.lr\n",
    "        if epoch >= 100:\n",
    "            lr /= 10\n",
    "        if epoch >= 150:\n",
    "            lr /= 10\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0ebb9b-2851-4c3c-82c9-b78155580fc1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-29T15:46:48.379550Z",
     "iopub.status.busy": "2023-08-29T15:46:48.379098Z",
     "iopub.status.idle": "2023-08-29T15:46:48.384841Z",
     "shell.execute_reply": "2023-08-29T15:46:48.383542Z",
     "shell.execute_reply.started": "2023-08-29T15:46:48.379515Z"
    },
    "tags": []
   },
   "source": [
    "### ModelUpdate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e955bded-e652-49a2-8650-97eba1b12a4f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T19:10:13.061251Z",
     "iopub.status.busy": "2023-09-27T19:10:13.060916Z",
     "iopub.status.idle": "2023-09-27T19:10:13.080267Z",
     "shell.execute_reply": "2023-09-27T19:10:13.079356Z",
     "shell.execute_reply.started": "2023-09-27T19:10:13.061214Z"
    }
   },
   "outputs": [],
   "source": [
    "class ModelUpdate(object):\n",
    "    def __init__(self, args, client_id, local_ep=1, dataset=None, idxs=None):\n",
    "        self.args = args\n",
    "        self.loss_func = nn.CrossEntropyLoss()\n",
    "        self.ldr_train = DataLoader(DatasetSplit(dataset, idxs), \n",
    "                                    batch_size=self.args.local_bs, shuffle=True)\n",
    "        self.local_ep = local_ep\n",
    "        self.client_id = client_id\n",
    "        \n",
    "    def train(self, pid, round_cur, local_net, net):\n",
    "        \n",
    "        net.train()\n",
    "        \n",
    "        # train and update\n",
    "        # weight_decay=self.args.l2_lambda\n",
    "        if self.args.l2_lambda != 0:\n",
    "            optimizer = torch.optim.SGD(net.parameters(), lr=self.args.lr, \n",
    "                                        weight_decay=self.args.l2_lambda,\n",
    "                                        momentum=self.args.momentum)\n",
    "        else:\n",
    "            optimizer = torch.optim.SGD(net.parameters(), lr=self.args.lr, \n",
    "                                        momentum=self.args.momentum)\n",
    "        epoch_loss = []\n",
    "\n",
    "        if self.args.sys_homo: \n",
    "            local_ep = self.local_ep\n",
    "        else:\n",
    "            local_ep = randint(self.args.min_le, self.args.max_le) \n",
    "        \n",
    "        for iter in range(local_ep):\n",
    "            print(f'\\n[ Current round {round_cur} Train epoch: {iter} ]')\n",
    "            batch_loss = []\n",
    "            correct = 0\n",
    "            train_size = 0\n",
    "\n",
    "            # adjust_learning_rate(self.args, optimizer, iter)\n",
    "            \n",
    "            for batch_idx, (images, labels) in enumerate(self.ldr_train):\n",
    "                \n",
    "                #C&W\n",
    "                images, labels = images.to(self.args.device), labels.to(self.args.device)\n",
    "                net.zero_grad()\n",
    "                log_probs = net(images) \n",
    "                loss = self.loss_func(log_probs, labels) \n",
    "                    \n",
    "                loss.backward()\n",
    "                \n",
    "                optimizer.step()\n",
    "                \n",
    "                # get the index of the max log-probability\n",
    "                y_pred = log_probs.data.max(1, keepdim=True)[1]\n",
    "                correct += y_pred.eq(labels.data.view_as(y_pred)).long().cpu().sum()\n",
    "                train_size += images.shape[0]\n",
    "                if self.args.verbose and batch_idx % 10 == 0:\n",
    "                    print('Round : {} Party {}: Update Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                        round_cur, pid, iter, batch_idx * len(images), len(self.ldr_train.dataset),\n",
    "                               100. * batch_idx / len(self.ldr_train), loss.item()))\n",
    "                batch_loss.append(loss.item())\n",
    "            epoch_loss.append(sum(batch_loss)/len(batch_loss))\n",
    "            print('\\nTotal adversarial train accuarcy:', 100. * correct / train_size)\n",
    "            print('\\nTotal adversarial train loss:', sum(batch_loss)/len(batch_loss))\n",
    "           \n",
    "        return net.state_dict(), sum(epoch_loss) / len(epoch_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96adb83-5256-4252-bfb9-c55c552e6857",
   "metadata": {},
   "source": [
    "### Adversarial_ModelUpdateAdversarial_ModelUpdate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ccd516-1fcd-4e64-982d-a6e25fe09f8f",
   "metadata": {},
   "source": [
    "- generate_adversarial_images\n",
    "- modify the label\n",
    "- calculate the loss\n",
    "- Take the first derivative of the loss func wrt to the model weights.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "45f611f1-c54f-4d4f-a1ef-5a2ac6df5d96",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T19:10:13.081814Z",
     "iopub.status.busy": "2023-09-27T19:10:13.081435Z",
     "iopub.status.idle": "2023-09-27T19:10:13.104792Z",
     "shell.execute_reply": "2023-09-27T19:10:13.104124Z",
     "shell.execute_reply.started": "2023-09-27T19:10:13.081777Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Adversarial_ModelUpdate(object):\n",
    "    def __init__(self, args, client_id, local_ep=1, dataset=None, idxs=None):\n",
    "        self.args = args\n",
    "        self.loss_func = nn.CrossEntropyLoss()\n",
    "        self.ldr_train = DataLoader(DatasetSplit(dataset, idxs), \n",
    "                                    batch_size=self.args.local_bs, shuffle=True)\n",
    "        self.local_ep = local_ep\n",
    "        self.client_id = client_id\n",
    "        \n",
    "    \n",
    "    def smooth_label(self, y):\n",
    "        '''\n",
    "        y: integer-base\n",
    "        '''\n",
    "        # convert y to one-hot encoding\n",
    "        y_onehot = F.one_hot(y, self.args.num_classes)\n",
    "        # smooth the one-hot encoding\n",
    "        y_smooth = (self.args.soft_label_clean) * y_onehot + (1 - self.args.soft_label_clean) / (self.args.num_classes)\n",
    "        # convert back to class labels\n",
    "        y_smooth = torch.argmax(y_smooth, dim=1)\n",
    "        return y_smooth\n",
    "\n",
    "    def train(self, pid, round_cur, local_net, net):\n",
    "        \n",
    "        net.train()\n",
    "        \n",
    "        # train and update\n",
    "        # weight_decay=self.args.l2_lambda\n",
    "        if self.args.l2_lambda != 0:\n",
    "            optimizer = torch.optim.SGD(net.parameters(), lr=self.args.lr, weight_decay=self.args.l2_lambda, momentum=self.args.momentum)\n",
    "        else:\n",
    "            optimizer = torch.optim.SGD(net.parameters(), lr=self.args.lr, momentum=self.args.momentum)\n",
    "        epoch_loss = []\n",
    "\n",
    "        if self.args.sys_homo: \n",
    "            local_ep = self.local_ep\n",
    "        else:\n",
    "            local_ep = randint(self.args.min_le, self.args.max_le) \n",
    "        \n",
    "        for iter in range(local_ep):\n",
    "            print(f'\\n[ Current round {round_cur} Train epoch: {iter} ]')\n",
    "            batch_loss = []\n",
    "            correct = 0\n",
    "            train_size = 0\n",
    "\n",
    "            adjust_learning_rate(self.args, optimizer, iter)\n",
    "            \n",
    "            for batch_idx, (images, labels) in enumerate(self.ldr_train):\n",
    "                \n",
    "                #C&W\n",
    "                images, labels = images.to(self.args.device), labels.to(self.args.device)\n",
    "\n",
    "                adversarial_images = generate_adversarial_images(self.args, \n",
    "                                                                    images, \n",
    "                                                                    labels, \n",
    "                                                                    net, \n",
    "                                                                    self.loss_func)\n",
    "    \n",
    "                adversarial_images = adversarial_images.to(self.args.device)\n",
    "    \n",
    "                labels_smooth = self.smooth_label(labels) #Test on Gaivi\n",
    "                \n",
    "                soft_label_list = torch.cat([labels_smooth, labels_smooth], dim=0)\n",
    "\n",
    "                soft_label_list = soft_label_list.to(self.args.device)\n",
    "\n",
    "                net.zero_grad()\n",
    "                log_probs = net(adversarial_images) #model predictions, no torch concaternation\n",
    "                loss = self.loss_func(log_probs, soft_label_list) #labels here 11 class and clean examples\n",
    "                    \n",
    "                loss.backward()\n",
    "                \n",
    "                optimizer.step()\n",
    "                \n",
    "                # get the index of the max log-probability\n",
    "                y_pred = log_probs.data.max(1, keepdim=True)[1]\n",
    "                correct += y_pred.eq(soft_label_list.data.view_as(y_pred)).long().cpu().sum()\n",
    "                train_size += adversarial_images.shape[0]\n",
    "                if self.args.verbose and batch_idx % 10 == 0:\n",
    "                    print('Round : {} Party {}: Update Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                        round_cur, pid, iter, batch_idx * len(images), len(self.ldr_train.dataset),\n",
    "                               100. * batch_idx / len(self.ldr_train), loss.item()))\n",
    "                batch_loss.append(loss.item())\n",
    "            epoch_loss.append(sum(batch_loss)/len(batch_loss))\n",
    "            print('\\nTotal adversarial train accuarcy:', 100. * correct / train_size)\n",
    "            print('\\nTotal adversarial train loss:', sum(batch_loss)/len(batch_loss))\n",
    "           \n",
    "        return net.state_dict(), sum(epoch_loss) / len(epoch_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8a7475-94cf-4d2d-950e-aedd55de2124",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Update global weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4e1f85-a11b-4c5c-a9f6-50401c0600ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-29T15:47:16.999097Z",
     "iopub.status.busy": "2023-08-29T15:47:16.998715Z",
     "iopub.status.idle": "2023-08-29T15:47:17.004729Z",
     "shell.execute_reply": "2023-08-29T15:47:17.001962Z",
     "shell.execute_reply.started": "2023-08-29T15:47:16.999067Z"
    },
    "tags": []
   },
   "source": [
    "#### FedAvg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "36aeef0c-5e82-4f42-aef1-678a16417eb1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T19:10:13.106250Z",
     "iopub.status.busy": "2023-09-27T19:10:13.105901Z",
     "iopub.status.idle": "2023-09-27T19:10:13.121730Z",
     "shell.execute_reply": "2023-09-27T19:10:13.120963Z",
     "shell.execute_reply.started": "2023-09-27T19:10:13.106214Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def FedAvg(w, args, c_global=None, res_caches=None):\n",
    "    w_avg = copy.deepcopy(w[0])\n",
    "    for k in w_avg.keys():\n",
    "        tmp = torch.zeros_like(w[0][k], dtype = torch.float32).to(args.device)\n",
    "        for i in range(len(w)):\n",
    "            tmp += w[i][k]\n",
    "        tmp = torch.true_divide(tmp, len(w))\n",
    "        w_avg[k].copy_(tmp)\n",
    "    if args.fed == 'scaffold' and c_global is not None and res_caches is not None:\n",
    "        if args.all_clients:\n",
    "            client_num_per_round = args.num_users\n",
    "        else:\n",
    "            client_num_per_round = max(int(args.frac * args.num_users), 1)\n",
    "        \n",
    "        # update global model\n",
    "        avg_weight = torch.tensor(\n",
    "                        [\n",
    "                            1 / client_num_per_round\n",
    "                            for _ in range(client_num_per_round)\n",
    "                        ],\n",
    "                        device=args.device,\n",
    "                    ) #by number of selected clients per round, not dependent on the local data size\n",
    "        # y_pred = net_glob(inputs).cpu()\n",
    "        # print(y_pred.detach().numpy())\n",
    "        # print(f'avg_weight: {avg_weight.cpu().detach().numpy()}')\n",
    "        c_delta_cache = list(zip(*res_caches))\n",
    "        # print(f'c_delta_cache {c_delta_cache}')\n",
    "        # update global control\n",
    "        for c_g, c_del in zip(c_global, c_delta_cache):\n",
    "            # print(f'before c_g {c_g.cpu().detach().numpy()}')\n",
    "            c_del = torch.sum(avg_weight * torch.stack(c_del, dim=-1), dim=-1) #delta_c = sum of avg_weight * delta_c_i\n",
    "            # print(f'c_del: {c_del.cpu().detach().numpy()}')\n",
    "            c_g.data += (\n",
    "                client_num_per_round / args.num_users\n",
    "            ) * c_del #c_global = |S| / N * c_delta\n",
    "            # print(f'c_g {c_g.cpu().detach().numpy()}')\n",
    "        return w_avg, c_global\n",
    "    return w_avg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad135cc-d1b3-476c-ba9f-aa284fe718c8",
   "metadata": {},
   "source": [
    "#### get_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e124d2fd-b001-4062-9fd6-9bf7a7b5b8aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T19:10:13.123166Z",
     "iopub.status.busy": "2023-09-27T19:10:13.122817Z",
     "iopub.status.idle": "2023-09-27T19:10:13.137195Z",
     "shell.execute_reply": "2023-09-27T19:10:13.136460Z",
     "shell.execute_reply.started": "2023-09-27T19:10:13.123129Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_scores(distance, th):\n",
    "    \"\"\"\n",
    "    Sorts the distances in an ordered list \n",
    "    and returns the list for use to \n",
    "    the fusion_collected_responses function\n",
    "\n",
    "    :param distance: List of distance vector\n",
    "    :type distance: `list`\n",
    "    :param th: Threshold\n",
    "    :return: list of summation of distances\n",
    "    :rtype: `list`\n",
    "    \"\"\"\n",
    "    distance.sort(axis=1)\n",
    "    \n",
    "    # print(f'sorted distance {distance}')\n",
    "    # the +1 is added to account for the zero entry (distance from itself)\n",
    "    return np.sum(distance[:, 0:th+1], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4afbb2e7-22d5-4283-912b-6c539331c3fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-29T22:46:34.822341Z",
     "iopub.status.busy": "2023-08-29T22:46:34.822017Z",
     "iopub.status.idle": "2023-08-29T22:46:34.829818Z",
     "shell.execute_reply": "2023-08-29T22:46:34.828853Z",
     "shell.execute_reply.started": "2023-08-29T22:46:34.822307Z"
    },
    "tags": []
   },
   "source": [
    "#### Util_ModelUpdate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3defcb5b-ce74-464e-ae9a-e61fb9b39f6e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T19:10:13.138667Z",
     "iopub.status.busy": "2023-09-27T19:10:13.138303Z",
     "iopub.status.idle": "2023-09-27T19:10:13.152977Z",
     "shell.execute_reply": "2023-09-27T19:10:13.152208Z",
     "shell.execute_reply.started": "2023-09-27T19:10:13.138630Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pickle import loads, dumps, dump\n",
    "class Util_ModelUpdate():\n",
    "    \"\"\"\n",
    "    Class to hold model update dictionary. Dictionary can only be accessed\n",
    "    using inbuild methods like `get` and `add`\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        \"\"\"\n",
    "        Initialize the dictionary and add updates.\n",
    "        :param kwargs: Dictionary of model-update specific arguments.\n",
    "        :type kwargs: `dict`\n",
    "        \"\"\"\n",
    "        self.__updates = {}\n",
    "        for key, value in kwargs.items():\n",
    "            # print(key)\n",
    "            # print(type(value))\n",
    "            self.add(key, value)\n",
    "\n",
    "    def add(self, key, value):\n",
    "        \"\"\"\n",
    "        Add update `value` for `key`\n",
    "\n",
    "        :param key: Identifier which represents the update\n",
    "        :type key: `str`\n",
    "        :param value: Content of the update\n",
    "        :type value: any ds/object which can be pickled\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.__updates[key] = dumps(value)\n",
    "\n",
    "        except Exception as ex:\n",
    "            logger.exception(ex)\n",
    "\n",
    "            logger.exception(\"Error occured while adding a update.\\\n",
    "                                Make sure model update data structure is picklable\")\n",
    "\n",
    "            raise ModelUpdateException(\"Error updating model update\")\n",
    "\n",
    "    def get(self, key):\n",
    "        \"\"\"\n",
    "        Get update value for given key from model update dictionary\n",
    "\n",
    "        :param key: Identifier which represents the update\n",
    "        :type key: `str`\n",
    "        :return: content of the update\n",
    "        :rtype: any ds/object after its unpickled\n",
    "        \"\"\"\n",
    "        if key not in self.__updates:\n",
    "            logger.error(\"Key \"+key+\" not found in model updates\")\n",
    "            raise ModelUpdateException(\n",
    "                \"Invalid key was requested from model update\")\n",
    "\n",
    "        ret_val = loads(self.__updates[key])\n",
    "        return ret_val\n",
    "\n",
    "    def exist_key(self, key):\n",
    "        \"\"\"\n",
    "        Check if a specified key is used in model update dictionary\n",
    "\n",
    "        :param key: Identifier which represents the update\n",
    "        :type key: `str`\n",
    "        :return: check result of existing the key\n",
    "        :rtype: True or False\n",
    "        \"\"\"\n",
    "        return True if key in self.__updates else False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84706432-0b25-49fa-9f8e-55c1621beedd",
   "metadata": {},
   "source": [
    "#### flatten_model_update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cb13b165-53be-447a-a2a9-4a002823a07a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T19:10:13.154240Z",
     "iopub.status.busy": "2023-09-27T19:10:13.153914Z",
     "iopub.status.idle": "2023-09-27T19:10:13.165288Z",
     "shell.execute_reply": "2023-09-27T19:10:13.164627Z",
     "shell.execute_reply.started": "2023-09-27T19:10:13.154215Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def flatten_model_update(w_local):\n",
    "    \"\"\"\n",
    "    Generates a flattened np array for all of the layerwise weights of an update\n",
    "\n",
    "    :param lst_layerwise_wts: List of layer weights\n",
    "    :type lst_layerwise_wts: `list`\n",
    "    :return: `np.array`\n",
    "    \"\"\"\n",
    "    lst_layerwise_wts = Util_ModelUpdate(weights=w_local).get('weights') #neural network and bias parameters\n",
    "    \n",
    "    # print(f'lst_layerwise_wts {type(lst_layerwise_wts)}')         \n",
    "    # print(f'lst_layerwise_wts {lst_layerwise_wts}')\n",
    "    wt_vector = []\n",
    "    for w in lst_layerwise_wts:\n",
    "        # print(f'w: type {type(w)} value {w}')\n",
    "        # t = w.flatten()\n",
    "        t = lst_layerwise_wts[w].flatten().cpu()\n",
    "        wt_vector = np.concatenate([wt_vector, t])\n",
    "    print(f'{wt_vector}\\n')\n",
    "    return wt_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f376bf-601c-4a93-bf16-080ab26f1b45",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-29T22:46:09.463697Z",
     "iopub.status.busy": "2023-08-29T22:46:09.463249Z",
     "iopub.status.idle": "2023-08-29T22:46:09.471529Z",
     "shell.execute_reply": "2023-08-29T22:46:09.470656Z",
     "shell.execute_reply.started": "2023-08-29T22:46:09.463659Z"
    },
    "tags": []
   },
   "source": [
    "#### Krum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "116a74b4-6bae-4ae7-81e6-298cea8bc968",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T19:10:13.166795Z",
     "iopub.status.busy": "2023-09-27T19:10:13.166426Z",
     "iopub.status.idle": "2023-09-27T19:10:13.181026Z",
     "shell.execute_reply": "2023-09-27T19:10:13.180350Z",
     "shell.execute_reply.started": "2023-09-27T19:10:13.166759Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def Krum(lst_model_updates, args, c_global=None, res_caches=None):\n",
    "    \"\"\"\n",
    "    Sorts the distances in an ordered list \n",
    "    and returns the list for use to \n",
    "    the fusion_collected_responses function\n",
    "\n",
    "    - w: A list containing model updates from different clients.\n",
    "    - args: A configuration object or dictionary containing various settings.\n",
    "    - c_global: Global model parameters (optional).\n",
    "    - res_caches: Cached values (optional).\n",
    "    :return: the selected model\n",
    "    :type: `nn.Module`\n",
    "    \"\"\"\n",
    "    num_updates = len(lst_model_updates)\n",
    "    distance = np.zeros((num_updates, num_updates), dtype=float)\n",
    "\n",
    "    lst_model_updates_flattened = []\n",
    "    for i in range(len(lst_model_updates)):\n",
    "        lst_model_updates_flattened.append(flatten_model_update(lst_model_updates[i]))\n",
    "\n",
    "    #Build distance matrix\n",
    "    for i in range(num_updates):\n",
    "        curr_vector = lst_model_updates_flattened[i]\n",
    "        for j in range(num_updates):\n",
    "            if j is not i:\n",
    "                distance[i, j] = \\\n",
    "                    np.square(\n",
    "                        np.linalg.norm(\n",
    "                        curr_vector - lst_model_updates_flattened[j]) # Default is L-2 norm\n",
    "                    ) #square distance \n",
    "\n",
    "    th = num_updates - args.byzantine_threshold - 2 #th means threshold, benign clients                \n",
    "    scores = get_scores(distance, th)\n",
    "    selected_idx = np.argmin(scores)\n",
    "    selected_net = lst_model_updates[selected_idx]\n",
    "    \n",
    "    # Print the 'distance' matrix\n",
    "    print(\"\\nDistance Matrix:\")\n",
    "    for row in distance:\n",
    "        print(row)\n",
    "    \n",
    "    print(f\"scores {scores}\")\n",
    "    print(f\"selected_idx {selected_idx}\")\n",
    "    \n",
    "    return selected_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1a38e89a-35bb-46f6-982f-65969600b781",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T19:10:13.182423Z",
     "iopub.status.busy": "2023-09-27T19:10:13.182071Z",
     "iopub.status.idle": "2023-09-27T19:10:13.196253Z",
     "shell.execute_reply": "2023-09-27T19:10:13.195445Z",
     "shell.execute_reply.started": "2023-09-27T19:10:13.182386Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# v1 = [0.3848, 0.2165, 0.179, -0.21, 0.2628]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c5e53338-ddaa-4525-8d8a-bb623023f891",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T19:10:13.197799Z",
     "iopub.status.busy": "2023-09-27T19:10:13.197392Z",
     "iopub.status.idle": "2023-09-27T19:10:13.209481Z",
     "shell.execute_reply": "2023-09-27T19:10:13.208820Z",
     "shell.execute_reply.started": "2023-09-27T19:10:13.197746Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# v2 = [-0.4749, 0.3494, -0.6478,-0.5333, -0.8635]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6409f697-e65f-4aba-ac16-526af5d6cd2a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T19:10:13.210842Z",
     "iopub.status.busy": "2023-09-27T19:10:13.210487Z",
     "iopub.status.idle": "2023-09-27T19:10:13.223455Z",
     "shell.execute_reply": "2023-09-27T19:10:13.222694Z",
     "shell.execute_reply.started": "2023-09-27T19:10:13.210804Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# square L2-distance \n",
    "# np.square(\n",
    "#                 np.linalg.norm(np.array(v1) - np.array(v2))\n",
    "#           ) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e79a707-0660-40aa-8809-fdcf4a0f5061",
   "metadata": {},
   "source": [
    "#### Test Krum with GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "45a929be-54dd-471d-9b65-8ff54a03a0d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T19:10:13.224963Z",
     "iopub.status.busy": "2023-09-27T19:10:13.224587Z",
     "iopub.status.idle": "2023-09-27T19:10:13.252747Z",
     "shell.execute_reply": "2023-09-27T19:10:13.251723Z",
     "shell.execute_reply.started": "2023-09-27T19:10:13.224926Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0\n",
      "\n",
      "layer_input.weight \t tensor([[ 0.2947, -0.3736]], device='cuda:0')\n",
      "layer_input.bias \t tensor([0.1801], device='cuda:0')\n",
      "layer_hidden.weight \t tensor([[0.6136]], device='cuda:0')\n",
      "layer_hidden.bias \t tensor([-0.2590], device='cuda:0')\n",
      "Model 1\n",
      "\n",
      "layer_input.weight \t tensor([[0.3409, 0.3530]], device='cuda:0')\n",
      "layer_input.bias \t tensor([0.3236], device='cuda:0')\n",
      "layer_hidden.weight \t tensor([[0.6977]], device='cuda:0')\n",
      "layer_hidden.bias \t tensor([-0.5504], device='cuda:0')\n",
      "Model 2\n",
      "\n",
      "layer_input.weight \t tensor([[0.4603, 0.2358]], device='cuda:0')\n",
      "layer_input.bias \t tensor([0.1099], device='cuda:0')\n",
      "layer_hidden.weight \t tensor([[0.3144]], device='cuda:0')\n",
      "layer_hidden.bias \t tensor([0.0370], device='cuda:0')\n",
      "Model 3\n",
      "\n",
      "layer_input.weight \t tensor([[0.5939, 0.5582]], device='cuda:0')\n",
      "layer_input.bias \t tensor([0.3992], device='cuda:0')\n",
      "layer_hidden.weight \t tensor([[0.6112]], device='cuda:0')\n",
      "layer_hidden.bias \t tensor([-0.9343], device='cuda:0')\n",
      "Model 4\n",
      "\n",
      "layer_input.weight \t tensor([[-0.2716,  0.2518]], device='cuda:0')\n",
      "layer_input.bias \t tensor([0.0842], device='cuda:0')\n",
      "layer_hidden.weight \t tensor([[-0.3589]], device='cuda:0')\n",
      "layer_hidden.bias \t tensor([-0.6112], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Define your linear regression models\n",
    "num_models = 5\n",
    "\n",
    "input_size = 2\n",
    "hidden_size = 1\n",
    "output_size = 1\n",
    "\n",
    "# Create a list of linear regression models (mocked with random parameters)\n",
    "lst_model_updates = []\n",
    "for i in range(num_models):   \n",
    "    net =  MLP(dim_in=input_size, dim_hidden=hidden_size, dim_out=output_size).to(args.device)\n",
    "    state_dict =  net.state_dict() #current weights and a dictionary object\n",
    "    lst_model_updates.append(state_dict)\n",
    "    print(f'Model {i}\\n')\n",
    "    for k in state_dict:\n",
    "        print(k, \"\\t\", state_dict[k])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7cdbef8a-aa50-47cf-b79b-27f33dee8c29",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T19:10:13.254052Z",
     "iopub.status.busy": "2023-09-27T19:10:13.253688Z",
     "iopub.status.idle": "2023-09-27T19:10:13.271307Z",
     "shell.execute_reply": "2023-09-27T19:10:13.269622Z",
     "shell.execute_reply.started": "2023-09-27T19:10:13.254014Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.29473367 -0.373568    0.18013968  0.61362445 -0.25898147]\n",
      "\n",
      "[ 0.34085208  0.35295913  0.32360089  0.69771278 -0.55036688]\n",
      "\n",
      "[0.46034127 0.23579425 0.1099237  0.31443894 0.03700936]\n",
      "\n",
      "[ 0.59390533  0.5581997   0.39917818  0.61123538 -0.93429756]\n",
      "\n",
      "[-0.2716195   0.2518141   0.08424059 -0.35886574 -0.61117744]\n",
      "\n",
      "\n",
      "Distance Matrix:\n",
      "[0.         0.58080105 0.64252599 1.46173013 1.79083449]\n",
      "[0.         0.26675268 0.5655729  0.64252599 1.56270119]\n",
      "[0.         0.5655729  0.58080105 1.23697805 1.41016815]\n",
      "[0.         0.26675268 1.23697805 1.46173013 1.98769384]\n",
      "[0.         1.41016815 1.56270119 1.79083449 1.98769384]\n",
      "scores [0.58080105 0.26675268 0.5655729  0.26675268 1.41016815]\n",
      "selected_idx 1\n",
      "<class 'collections.OrderedDict'>\n"
     ]
    }
   ],
   "source": [
    "# Test the Krum function\n",
    "results = Krum(lst_model_updates, args)\n",
    "print(type(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ae21c6b3-2887-41bb-8172-30c2bf0483db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T19:10:13.272776Z",
     "iopub.status.busy": "2023-09-27T19:10:13.272414Z",
     "iopub.status.idle": "2023-09-27T19:10:13.282917Z",
     "shell.execute_reply": "2023-09-27T19:10:13.281814Z",
     "shell.execute_reply.started": "2023-09-27T19:10:13.272739Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global_net Weights:\n",
      "layer_input.weight \t tensor([[0.3409, 0.3530]])\n",
      "layer_input.bias \t tensor([0.3236])\n",
      "layer_hidden.weight \t tensor([[0.6977]])\n",
      "layer_hidden.bias \t tensor([-0.5504])\n"
     ]
    }
   ],
   "source": [
    "global_net =  MLP(dim_in=input_size, dim_hidden=hidden_size, dim_out=output_size)\n",
    "\n",
    "global_net.load_state_dict(results, strict=True)\n",
    "\n",
    "print(\"global_net Weights:\")\n",
    "state_dict =  global_net.state_dict() #current weights and a dictionary object\n",
    "for k in state_dict:\n",
    "    print(k, \"\\t\", state_dict[k])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab1e064-b126-4362-bc3a-055dc5ca9ce1",
   "metadata": {},
   "source": [
    "#### CoordinateMedian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0fa6388d-8668-4ed0-afa8-888cbc548837",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T19:10:13.284191Z",
     "iopub.status.busy": "2023-09-27T19:10:13.283842Z",
     "iopub.status.idle": "2023-09-27T19:10:13.297293Z",
     "shell.execute_reply": "2023-09-27T19:10:13.296620Z",
     "shell.execute_reply.started": "2023-09-27T19:10:13.284153Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def CoordinateMedian(lst_model_updates, args, c_global=None, res_caches=None):\n",
    "    \"\"\"\n",
    "    the averaging aggregation is performed using Coordinate-Median policy model weights.\n",
    "    Implements the algorithm in Byzantine-Robust Distributed Learning: \n",
    "    Towards Optimal Statistical Rates: https://arxiv.org/pdf/1803.01498.pdf\n",
    "\n",
    "    - w: A list containing model updates from different clients.\n",
    "    - args: A configuration object or dictionary containing various settings.\n",
    "    - c_global: Global model parameters (optional).\n",
    "    - res_caches: Cached values (optional).\n",
    "    :return: results after aggregation\n",
    "    :type: `list`\n",
    "    \"\"\"\n",
    "    parameters = []\n",
    "    results = []\n",
    "    \n",
    "    for i in range(len(lst_model_updates)):\n",
    "        w_local = lst_model_updates[i]\n",
    "        lst_layerwise_wts = Util_ModelUpdate(weights=w_local).get('weights') #list of layer weights\n",
    "        # print(f'Model {i} {lst_layerwise_wts}')\n",
    "        parameters.append(lst_layerwise_wts)\n",
    "    \n",
    "    # # print(f'parameters {parameters}\\n')\n",
    "    # for layer in zip(*parameters):\n",
    "    #     print(f' layer {type(layer)} layer {layer}')\n",
    "        \n",
    "    for layer in zip(*parameters):\n",
    "        # print(f' layer {layer}')\n",
    "        \n",
    "        tensors = []\n",
    "        temp = []\n",
    "        for i, tensor in enumerate(layer):\n",
    "            # print(f'tensor {tensor}')\n",
    "            tensors.append(parameters[i][tensor])\n",
    "            temp.append(np.array(parameters[i][tensor].cpu()))\n",
    "        \n",
    "        # print(f'list of tensors {tensors}\\n')\n",
    "        # print(f'layer {layer} the corresponding numpy array {temp}\\n')\n",
    "        \n",
    "        results.append(np.median(temp, axis=0))\n",
    "    \n",
    "    # print(f'results {results}\\n')\n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28dec9b-b80e-4c00-97cd-1a1bcf59637e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-30T02:45:53.816002Z",
     "iopub.status.busy": "2023-08-30T02:45:53.815559Z",
     "iopub.status.idle": "2023-08-30T02:45:53.822632Z",
     "shell.execute_reply": "2023-08-30T02:45:53.821635Z",
     "shell.execute_reply.started": "2023-08-30T02:45:53.815964Z"
    },
    "tags": []
   },
   "source": [
    "#### Test CoordinateMedian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5b79b8b1-0eba-4791-a7d9-0c7dd8fa9ffb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T19:10:13.298754Z",
     "iopub.status.busy": "2023-09-27T19:10:13.298394Z",
     "iopub.status.idle": "2023-09-27T19:10:13.317569Z",
     "shell.execute_reply": "2023-09-27T19:10:13.316849Z",
     "shell.execute_reply.started": "2023-09-27T19:10:13.298717Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test the CoordinateMedian function\n",
    "results = CoordinateMedian(lst_model_updates, args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4af6b019-6062-49a0-b955-872e14cdd276",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T19:10:13.319046Z",
     "iopub.status.busy": "2023-09-27T19:10:13.318694Z",
     "iopub.status.idle": "2023-09-27T19:10:13.330250Z",
     "shell.execute_reply": "2023-09-27T19:10:13.329087Z",
     "shell.execute_reply.started": "2023-09-27T19:10:13.319009Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global_net Weights:\n",
      "layer_input.weight \t tensor([[0.3409, 0.2518]])\n",
      "layer_input.bias \t tensor([0.1801])\n",
      "layer_hidden.weight \t tensor([[0.6112]])\n",
      "layer_hidden.bias \t tensor([-0.5504])\n"
     ]
    }
   ],
   "source": [
    "#Load the model using the results\n",
    "global_net =  MLP(dim_in=input_size, dim_hidden=hidden_size, dim_out=output_size)\n",
    "state_dict =  global_net.state_dict() #current weights and a dictionary object\n",
    "\n",
    "for k, v in zip(state_dict.keys(), results):\n",
    "    v = torch.from_numpy(v) #Create tensors\n",
    "    v = v.to(args.device)\n",
    "    v.requires_grad = True\n",
    "    state_dict[k] = v\n",
    "global_net.load_state_dict(state_dict, strict=True)\n",
    "\n",
    "print(\"global_net Weights:\")\n",
    "state_dict =  global_net.state_dict() #current weights and a dictionary object\n",
    "for k in state_dict:\n",
    "    print(k, \"\\t\", state_dict[k])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb613e3-c1ba-40b0-9d91-2985afca9f7b",
   "metadata": {},
   "source": [
    "## Initialization using Data Sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5fac4ec7-e8c0-4c26-9813-2c9d84d65da3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T19:10:13.331506Z",
     "iopub.status.busy": "2023-09-27T19:10:13.331144Z",
     "iopub.status.idle": "2023-09-27T19:10:13.340468Z",
     "shell.execute_reply": "2023-09-27T19:10:13.339758Z",
     "shell.execute_reply.started": "2023-09-27T19:10:13.331448Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "net_glob.train()\n",
    "\n",
    "# copy weights\n",
    "w_glob = net_glob.state_dict()\n",
    "        \n",
    "# # initialization stage of FedShare\n",
    "# print('initialization stage of FedShare')\n",
    "# #share a warm-up model trained on the global dataset, dg_idx,\n",
    "# initialization_stage = ModelUpdate(args=args, \n",
    "#                                   client_id=9999,\n",
    "#                                    local_ep=args.local_ep, \n",
    "#                                    dataset=dataset, \n",
    "#                                    idxs=set(dg_idx))\n",
    "# w_glob, _ = initialization_stage.train(pid=999, \n",
    "#                                        round_cur=9999, \n",
    "#                                        local_net = copy.deepcopy(net_glob).to(args.device), \n",
    "#                                        net = copy.deepcopy(net_glob).to(args.device))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a93ae5-90d5-4558-9605-6457bd4d6041",
   "metadata": {},
   "source": [
    "## Test image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae69e31c-a4eb-4814-832f-92c25d5c0d42",
   "metadata": {},
   "source": [
    "### Method 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5f4986b5-642b-4810-9e64-650a97f335e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T19:10:13.341803Z",
     "iopub.status.busy": "2023-09-27T19:10:13.341440Z",
     "iopub.status.idle": "2023-09-27T19:10:15.056783Z",
     "shell.execute_reply": "2023-09-27T19:10:15.055037Z",
     "shell.execute_reply.started": "2023-09-27T19:10:13.341766Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: \n",
      "Accuracy: 106/1000 (10.60%)\n",
      "\n",
      "\n",
      "FGSM -- Adversarial Test set as a classifier: \n",
      "Adv Accuracy: 97/1000 (9.70%)\n",
      "\n",
      "\n",
      "Number of correct classified clean examples(as compared to clean predictions): 106/1000\n",
      "\n",
      "Number of correct classified adversarial examples(as compared to clean predictions): 97/1000\n"
     ]
    }
   ],
   "source": [
    "net_glob.load_state_dict(w_glob)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "###\n",
    "test_idxs = np.arange(1000)\n",
    "###\n",
    "acc_test, adv_acc_test,(_) = test_img(net_glob, dataset_test, \n",
    "                                                       test_idxs,\n",
    "                                                       args, loss_fn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bcfd3b1-2dc3-44c0-90bd-d4de3f52932a",
   "metadata": {},
   "source": [
    "### Method 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a6e24112-c4fc-4383-a71b-062906997e79",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T19:10:15.058258Z",
     "iopub.status.busy": "2023-09-27T19:10:15.057900Z",
     "iopub.status.idle": "2023-09-27T19:10:16.018948Z",
     "shell.execute_reply": "2023-09-27T19:10:16.017265Z",
     "shell.execute_reply.started": "2023-09-27T19:10:15.058218Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: \n",
      "Accuracy on benign test examples: 106/1000 (10.60%)\n",
      "\n",
      "\n",
      "Test set: \n",
      "Accuracy on Gaussin noise test examples: 14/1000 (1.40%)\n",
      "\n",
      "\n",
      "Test accuracy for noisy FGSM: \n",
      "Adv Accuracy: 9.699999809265137/1000 (9.70%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "###\n",
    "test_idxs = np.arange(1000)\n",
    "###\n",
    "accuracy, Gaussian_acc, FGSM_acc_noise, (_) = test_img_noise(net_glob, dataset_test,\n",
    "                                                        test_idxs,\n",
    "                                                        args, loss_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30564981-f035-4b58-a6a2-4898db8c132a",
   "metadata": {},
   "source": [
    "## Local data partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "fd8d8e15-0b5d-4476-8b52-87e4a98f0089",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T19:10:16.020351Z",
     "iopub.status.busy": "2023-09-27T19:10:16.020004Z",
     "iopub.status.idle": "2023-09-27T19:10:16.026854Z",
     "shell.execute_reply": "2023-09-27T19:10:16.025772Z",
     "shell.execute_reply.started": "2023-09-27T19:10:16.020312Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([0, 1, 2, 3, 4])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_users.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9691446-2b90-426a-92e3-20f92baffd1d",
   "metadata": {},
   "source": [
    "### uniform_distribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ff90a084-3b2c-48c5-8ff2-678723e2cf8a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T19:10:16.028100Z",
     "iopub.status.busy": "2023-09-27T19:10:16.027763Z",
     "iopub.status.idle": "2023-09-27T19:10:16.045442Z",
     "shell.execute_reply": "2023-09-27T19:10:16.044526Z",
     "shell.execute_reply.started": "2023-09-27T19:10:16.028064Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def uniform_distribute(dataset, args): \n",
    "    globally_shared_data_idx = []\n",
    "    \n",
    "    idxs = np.arange(len(dataset))\n",
    "    \n",
    "    if args.dataset == \"mnist\":\n",
    "        labels = dataset.targets.numpy()\n",
    "    elif args.dataset == \"cifar\" or args.dataset == \"adv_cifar\" or args.dataset == \"cifar_cw_3\" or args.dataset == \"ntga_cifar\" :\n",
    "        labels = np.array(dataset.targets)\n",
    "    else:\n",
    "        exit('uniform_distribute - Error: unrecognized dataset')\n",
    "    \n",
    "    idxs_labels = np.vstack((idxs, labels))\n",
    "    idxs_labels = idxs_labels[:,idxs_labels[1,:].argsort()]\n",
    "\n",
    "    idxs = idxs_labels[0]\n",
    "    labels = idxs_labels[1]\n",
    "    \n",
    "    for i in range(args.num_classes):\n",
    "        specific_class = np.extract(labels == i, idxs)\n",
    "        globally_shared_data = np.random.choice(specific_class, int(args.alpha * args.classwise), replace=False)\n",
    "        \n",
    "        globally_shared_data_idx = globally_shared_data_idx + list(globally_shared_data)\n",
    "    \n",
    "    return globally_shared_data_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "afa4d952-e433-46d6-be33-1a2f7ae61e8d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T19:10:16.046749Z",
     "iopub.status.busy": "2023-09-27T19:10:16.046390Z",
     "iopub.status.idle": "2023-09-27T19:10:16.057112Z",
     "shell.execute_reply": "2023-09-27T19:10:16.056361Z",
     "shell.execute_reply.started": "2023-09-27T19:10:16.046713Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#### dict_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7830a0af-b0b1-4ccb-813f-e1c42d62ee80",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T19:10:16.058528Z",
     "iopub.status.busy": "2023-09-27T19:10:16.058168Z",
     "iopub.status.idle": "2023-09-27T19:10:16.075544Z",
     "shell.execute_reply": "2023-09-27T19:10:16.074373Z",
     "shell.execute_reply.started": "2023-09-27T19:10:16.058491Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "party0 local: 10000\n",
      "party1 local: 10000\n",
      "party2 local: 10000\n",
      "party3 local: 10000\n",
      "party4 local: 10000\n"
     ]
    }
   ],
   "source": [
    "# share_idx = uniform_distribute(dg, args)\n",
    "for idx in range(args.num_users):\n",
    "    print(f'party{idx} local: {len(dict_users[idx])}')\n",
    "    # print(f'party{idx} share: {len(share_idx)}')\n",
    "    # local_train_idx = set(list(dict_users[idx]) + share_idx)\n",
    "    # print(f'party{idx} combined set (no repeat): {len(local_train_idx)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ace7bf8-08ab-4d8a-982d-c73ac84e7ef3",
   "metadata": {},
   "source": [
    "# Main training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "894b7bb2-a4eb-4c9f-8935-43f355c371bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T19:10:16.076850Z",
     "iopub.status.busy": "2023-09-27T19:10:16.076526Z",
     "iopub.status.idle": "2023-09-27T19:11:39.685548Z",
     "shell.execute_reply": "2023-09-27T19:11:39.684203Z",
     "shell.execute_reply.started": "2023-09-27T19:10:16.076827Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregation over all clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attacker Indices: [1 2]\n",
      "Non-Attacker Indices: [0, 3, 4]\n",
      "\n",
      "[ Current round 0 Train epoch: 0 ]\n",
      "Round : 0 Party 0: Update Epoch: 0 [0/10000 (0%)]\tLoss: 2.343992\n",
      "Round : 0 Party 0: Update Epoch: 0 [1280/10000 (13%)]\tLoss: 2.233247\n",
      "Round : 0 Party 0: Update Epoch: 0 [2560/10000 (25%)]\tLoss: 2.087997\n",
      "Round : 0 Party 0: Update Epoch: 0 [3840/10000 (38%)]\tLoss: 2.078186\n",
      "Round : 0 Party 0: Update Epoch: 0 [5120/10000 (51%)]\tLoss: 1.956667\n",
      "Round : 0 Party 0: Update Epoch: 0 [6400/10000 (63%)]\tLoss: 1.932101\n",
      "Round : 0 Party 0: Update Epoch: 0 [7680/10000 (76%)]\tLoss: 1.876982\n",
      "Round : 0 Party 0: Update Epoch: 0 [8960/10000 (89%)]\tLoss: 1.798764\n",
      "\n",
      "Total adversarial train accuarcy: tensor(24.5400)\n",
      "\n",
      "Total adversarial train loss: 2.005402970917617\n",
      "\n",
      "[ Current round 0 Train epoch: 0 ]\n",
      "Round : 0 Party 3: Update Epoch: 0 [0/10000 (0%)]\tLoss: 2.379504\n",
      "Round : 0 Party 3: Update Epoch: 0 [1280/10000 (13%)]\tLoss: 2.205266\n",
      "Round : 0 Party 3: Update Epoch: 0 [2560/10000 (25%)]\tLoss: 2.181103\n",
      "Round : 0 Party 3: Update Epoch: 0 [3840/10000 (38%)]\tLoss: 2.034467\n",
      "Round : 0 Party 3: Update Epoch: 0 [5120/10000 (51%)]\tLoss: 1.974853\n",
      "Round : 0 Party 3: Update Epoch: 0 [6400/10000 (63%)]\tLoss: 2.003553\n",
      "Round : 0 Party 3: Update Epoch: 0 [7680/10000 (76%)]\tLoss: 1.895307\n",
      "Round : 0 Party 3: Update Epoch: 0 [8960/10000 (89%)]\tLoss: 1.820668\n",
      "\n",
      "Total adversarial train accuarcy: tensor(24.3800)\n",
      "\n",
      "Total adversarial train loss: 2.027866183956967\n",
      "\n",
      "[ Current round 0 Train epoch: 0 ]\n",
      "Round : 0 Party 4: Update Epoch: 0 [0/10000 (0%)]\tLoss: 2.428010\n",
      "Round : 0 Party 4: Update Epoch: 0 [1280/10000 (13%)]\tLoss: 2.274713\n",
      "Round : 0 Party 4: Update Epoch: 0 [2560/10000 (25%)]\tLoss: 2.152005\n",
      "Round : 0 Party 4: Update Epoch: 0 [3840/10000 (38%)]\tLoss: 2.086160\n",
      "Round : 0 Party 4: Update Epoch: 0 [5120/10000 (51%)]\tLoss: 2.008635\n",
      "Round : 0 Party 4: Update Epoch: 0 [6400/10000 (63%)]\tLoss: 1.946032\n",
      "Round : 0 Party 4: Update Epoch: 0 [7680/10000 (76%)]\tLoss: 1.868967\n",
      "Round : 0 Party 4: Update Epoch: 0 [8960/10000 (89%)]\tLoss: 1.858437\n",
      "\n",
      "Total adversarial train accuarcy: tensor(24.4200)\n",
      "\n",
      "Total adversarial train loss: 2.021101198618925\n",
      "\n",
      "[ Current round 0 Train epoch: 0 ]\n",
      "Round : 0 Party 1: Update Epoch: 0 [0/10000 (0%)]\tLoss: 2.346225\n",
      "Round : 0 Party 1: Update Epoch: 0 [1280/10000 (13%)]\tLoss: 2.201477\n",
      "Round : 0 Party 1: Update Epoch: 0 [2560/10000 (25%)]\tLoss: 2.073141\n",
      "Round : 0 Party 1: Update Epoch: 0 [3840/10000 (38%)]\tLoss: 2.096160\n",
      "Round : 0 Party 1: Update Epoch: 0 [5120/10000 (51%)]\tLoss: 1.863054\n",
      "Round : 0 Party 1: Update Epoch: 0 [6400/10000 (63%)]\tLoss: 1.833596\n",
      "Round : 0 Party 1: Update Epoch: 0 [7680/10000 (76%)]\tLoss: 1.926789\n",
      "Round : 0 Party 1: Update Epoch: 0 [8960/10000 (89%)]\tLoss: 1.730082\n",
      "\n",
      "Total adversarial train accuarcy: tensor(25.1200)\n",
      "\n",
      "Total adversarial train loss: 2.018638183798971\n",
      "\n",
      "[ Current round 0 Train epoch: 0 ]\n",
      "Round : 0 Party 2: Update Epoch: 0 [0/10000 (0%)]\tLoss: 2.376362\n",
      "Round : 0 Party 2: Update Epoch: 0 [1280/10000 (13%)]\tLoss: 2.220477\n",
      "Round : 0 Party 2: Update Epoch: 0 [2560/10000 (25%)]\tLoss: 2.178389\n",
      "Round : 0 Party 2: Update Epoch: 0 [3840/10000 (38%)]\tLoss: 2.104135\n",
      "Round : 0 Party 2: Update Epoch: 0 [5120/10000 (51%)]\tLoss: 1.965356\n",
      "Round : 0 Party 2: Update Epoch: 0 [6400/10000 (63%)]\tLoss: 1.930976\n",
      "Round : 0 Party 2: Update Epoch: 0 [7680/10000 (76%)]\tLoss: 1.832939\n",
      "Round : 0 Party 2: Update Epoch: 0 [8960/10000 (89%)]\tLoss: 1.842156\n",
      "\n",
      "Total adversarial train accuarcy: tensor(24.2500)\n",
      "\n",
      "Total adversarial train loss: 2.023513649083391\n",
      "[-0.0328742  -0.11633403  0.15845741 ...  0.0423677   0.03562338\n",
      " -0.02796263]\n",
      "\n",
      "[-0.03449732 -0.11772724  0.15713181 ...  0.04257238  0.03538925\n",
      " -0.02829916]\n",
      "\n",
      "[-0.03286906 -0.1155092   0.16075887 ...  0.04327863  0.03597924\n",
      " -0.02780391]\n",
      "\n",
      "[-0.03326198 -0.11582816  0.15975989 ...  0.04207658  0.03598493\n",
      " -0.02791793]\n",
      "\n",
      "[-0.0321724  -0.11702063  0.15862183 ...  0.04244774  0.03572035\n",
      " -0.02764652]\n",
      "\n",
      "\n",
      "Distance Matrix:\n",
      "[ 0.         10.74091497 11.05849357 13.33552083 13.35020243]\n",
      "[ 0.         11.05849357 11.77218883 12.51669901 12.99967395]\n",
      "[ 0.         11.77218883 11.94641606 12.20079831 13.33552083]\n",
      "[ 0.         10.74091497 11.94641606 12.99967395 13.17141579]\n",
      "[ 0.         12.20079831 12.51669901 13.17141579 13.35020243]\n",
      "scores [10.74091497 11.05849357 11.77218883 10.74091497 12.20079831]\n",
      "selected_idx 0\n",
      "\n",
      "Test set: \n",
      "Accuracy: 293/1000 (29.30%)\n",
      "\n",
      "\n",
      "FGSM -- Adversarial Test set as a classifier: \n",
      "Adv Accuracy: 6/1000 (0.60%)\n",
      "\n",
      "\n",
      "Number of correct classified clean examples(as compared to clean predictions): 293/1000\n",
      "\n",
      "Number of correct classified adversarial examples(as compared to clean predictions): 6/1000\n",
      "\n",
      "Test set: \n",
      "Accuracy on benign test examples: 293/1000 (29.30%)\n",
      "\n",
      "\n",
      "Test set: \n",
      "Accuracy on Gaussin noise test examples: 34/1000 (3.40%)\n",
      "\n",
      "\n",
      "Test accuracy for noisy FGSM: \n",
      "Adv Accuracy: 0.6000000238418579/1000 (0.60%)\n",
      "\n",
      "Round: 0\n",
      "Average train loss over [2.005402970917617, 2.027866183956967, 2.021101198618925, 2.018638183798971, 2.023513649083391] parties: 10.096522186375871\n",
      "Test accuracy: 29.299999237060547\n",
      "Adv Test accuracy: 0.6000000238418579\n",
      "Adv Test accuracy With Noise: 0.6000000238418579\n",
      "Total time for the training: 0:00:41.311683 seconds ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|     | 1/2 [00:41<00:41, 41.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The final model saved to:  ./save/Krum_0.031_cifar_customized_resnet18_2_1_nParties_3_iid__1000_0_model_2023-09-27T15-10-16.pt\n",
      "Model Saved!\n",
      "filepath  ./save/Krum_0.031_cifar_customized_resnet18_$2_1_nParties_3_iid_1000_0_2023-09-27T15-10-16.out\n",
      "The output file saved to:  ./save/Krum_0.031_cifar_customized_resnet18_$2_1_nParties_3_iid_1000_0_2023-09-27T15-10-16.out\n",
      "Attacker Indices: [3 2]\n",
      "Non-Attacker Indices: [0, 1, 4]\n",
      "\n",
      "[ Current round 1 Train epoch: 0 ]\n",
      "Round : 1 Party 0: Update Epoch: 0 [0/10000 (0%)]\tLoss: 1.889886\n",
      "Round : 1 Party 0: Update Epoch: 0 [1280/10000 (13%)]\tLoss: 1.713759\n",
      "Round : 1 Party 0: Update Epoch: 0 [2560/10000 (25%)]\tLoss: 1.654663\n",
      "Round : 1 Party 0: Update Epoch: 0 [3840/10000 (38%)]\tLoss: 1.725882\n",
      "Round : 1 Party 0: Update Epoch: 0 [5120/10000 (51%)]\tLoss: 1.694599\n",
      "Round : 1 Party 0: Update Epoch: 0 [6400/10000 (63%)]\tLoss: 1.599142\n",
      "Round : 1 Party 0: Update Epoch: 0 [7680/10000 (76%)]\tLoss: 1.655184\n",
      "Round : 1 Party 0: Update Epoch: 0 [8960/10000 (89%)]\tLoss: 1.711910\n",
      "\n",
      "Total adversarial train accuarcy: tensor(37.7800)\n",
      "\n",
      "Total adversarial train loss: 1.6649900508832327\n",
      "\n",
      "[ Current round 1 Train epoch: 0 ]\n",
      "Round : 1 Party 1: Update Epoch: 0 [0/10000 (0%)]\tLoss: 1.750136\n",
      "Round : 1 Party 1: Update Epoch: 0 [1280/10000 (13%)]\tLoss: 1.664330\n",
      "Round : 1 Party 1: Update Epoch: 0 [2560/10000 (25%)]\tLoss: 1.641012\n",
      "Round : 1 Party 1: Update Epoch: 0 [3840/10000 (38%)]\tLoss: 1.668742\n",
      "Round : 1 Party 1: Update Epoch: 0 [5120/10000 (51%)]\tLoss: 1.664033\n",
      "Round : 1 Party 1: Update Epoch: 0 [6400/10000 (63%)]\tLoss: 1.625826\n",
      "Round : 1 Party 1: Update Epoch: 0 [7680/10000 (76%)]\tLoss: 1.568049\n",
      "Round : 1 Party 1: Update Epoch: 0 [8960/10000 (89%)]\tLoss: 1.633526\n",
      "\n",
      "Total adversarial train accuarcy: tensor(36.0600)\n",
      "\n",
      "Total adversarial train loss: 1.6809439508220818\n",
      "\n",
      "[ Current round 1 Train epoch: 0 ]\n",
      "Round : 1 Party 4: Update Epoch: 0 [0/10000 (0%)]\tLoss: 1.707394\n",
      "Round : 1 Party 4: Update Epoch: 0 [1280/10000 (13%)]\tLoss: 1.647799\n",
      "Round : 1 Party 4: Update Epoch: 0 [2560/10000 (25%)]\tLoss: 1.709416\n",
      "Round : 1 Party 4: Update Epoch: 0 [3840/10000 (38%)]\tLoss: 1.789058\n",
      "Round : 1 Party 4: Update Epoch: 0 [5120/10000 (51%)]\tLoss: 1.693631\n",
      "Round : 1 Party 4: Update Epoch: 0 [6400/10000 (63%)]\tLoss: 1.605213\n",
      "Round : 1 Party 4: Update Epoch: 0 [7680/10000 (76%)]\tLoss: 1.615291\n",
      "Round : 1 Party 4: Update Epoch: 0 [8960/10000 (89%)]\tLoss: 1.524124\n",
      "\n",
      "Total adversarial train accuarcy: tensor(37.1100)\n",
      "\n",
      "Total adversarial train loss: 1.6694608338271515\n",
      "\n",
      "[ Current round 1 Train epoch: 0 ]\n",
      "Round : 1 Party 3: Update Epoch: 0 [0/10000 (0%)]\tLoss: 1.835071\n",
      "Round : 1 Party 3: Update Epoch: 0 [1280/10000 (13%)]\tLoss: 1.888394\n",
      "Round : 1 Party 3: Update Epoch: 0 [2560/10000 (25%)]\tLoss: 1.771375\n",
      "Round : 1 Party 3: Update Epoch: 0 [3840/10000 (38%)]\tLoss: 1.695215\n",
      "Round : 1 Party 3: Update Epoch: 0 [5120/10000 (51%)]\tLoss: 1.648123\n",
      "Round : 1 Party 3: Update Epoch: 0 [6400/10000 (63%)]\tLoss: 1.598426\n",
      "Round : 1 Party 3: Update Epoch: 0 [7680/10000 (76%)]\tLoss: 1.696007\n",
      "Round : 1 Party 3: Update Epoch: 0 [8960/10000 (89%)]\tLoss: 1.507635\n",
      "\n",
      "Total adversarial train accuarcy: tensor(36.2500)\n",
      "\n",
      "Total adversarial train loss: 1.6838742600211614\n",
      "\n",
      "[ Current round 1 Train epoch: 0 ]\n",
      "Round : 1 Party 2: Update Epoch: 0 [0/10000 (0%)]\tLoss: 1.811203\n",
      "Round : 1 Party 2: Update Epoch: 0 [1280/10000 (13%)]\tLoss: 1.549576\n",
      "Round : 1 Party 2: Update Epoch: 0 [2560/10000 (25%)]\tLoss: 1.562653\n",
      "Round : 1 Party 2: Update Epoch: 0 [3840/10000 (38%)]\tLoss: 1.580956\n",
      "Round : 1 Party 2: Update Epoch: 0 [5120/10000 (51%)]\tLoss: 1.682455\n",
      "Round : 1 Party 2: Update Epoch: 0 [6400/10000 (63%)]\tLoss: 1.579595\n",
      "Round : 1 Party 2: Update Epoch: 0 [7680/10000 (76%)]\tLoss: 1.610312\n",
      "Round : 1 Party 2: Update Epoch: 0 [8960/10000 (89%)]\tLoss: 1.657123\n",
      "\n",
      "Total adversarial train accuarcy: tensor(37.1500)\n",
      "\n",
      "Total adversarial train loss: 1.6753768377666232\n",
      "[-0.03212805 -0.11538725  0.15875219 ...  0.04278676  0.03545386\n",
      " -0.02869053]\n",
      "\n",
      "[-0.03414459 -0.11722808  0.15787312 ...  0.04313309  0.03563272\n",
      " -0.02806885]\n",
      "\n",
      "[-0.03108547 -0.11530922  0.15970145 ...  0.04275442  0.03561686\n",
      " -0.02852015]\n",
      "\n",
      "[-0.03232791 -0.11578526  0.15895343 ...  0.04299504  0.03556253\n",
      " -0.02802947]\n",
      "\n",
      "[-0.03170716 -0.1154965   0.15988287 ...  0.04327971  0.03530007\n",
      " -0.02894924]\n",
      "\n",
      "\n",
      "Distance Matrix:\n",
      "[0.         6.61047731 6.91964561 7.17325671 7.17628818]\n",
      "[0.         6.30453315 6.91964561 6.9855101  7.14526667]\n",
      "[0.         6.61047731 6.78093708 7.09277728 7.14526667]\n",
      "[0.         6.78093708 6.80222214 6.9855101  7.17325671]\n",
      "[0.         6.30453315 6.80222214 7.09277728 7.17628818]\n",
      "scores [6.61047731 6.30453315 6.61047731 6.78093708 6.30453315]\n",
      "selected_idx 1\n",
      "\n",
      "Test set: \n",
      "Accuracy: 377/1000 (37.70%)\n",
      "\n",
      "\n",
      "FGSM -- Adversarial Test set as a classifier: \n",
      "Adv Accuracy: 4/1000 (0.40%)\n",
      "\n",
      "\n",
      "Number of correct classified clean examples(as compared to clean predictions): 377/1000\n",
      "\n",
      "Number of correct classified adversarial examples(as compared to clean predictions): 4/1000\n",
      "\n",
      "Test set: \n",
      "Accuracy on benign test examples: 377/1000 (37.70%)\n",
      "\n",
      "\n",
      "Test set: \n",
      "Accuracy on Gaussin noise test examples: 49/1000 (4.90%)\n",
      "\n",
      "\n",
      "Test accuracy for noisy FGSM: \n",
      "Adv Accuracy: 0.4000000059604645/1000 (0.40%)\n",
      "\n",
      "Round: 1\n",
      "Average train loss over [1.6649900508832327, 1.6809439508220818, 1.6694608338271515, 1.6838742600211614, 1.6753768377666232] parties: 8.37464593332025\n",
      "Test accuracy: 37.70000076293945\n",
      "Adv Test accuracy: 0.4000000059604645\n",
      "Adv Test accuracy With Noise: 0.4000000059604645\n",
      "Total time for the training: 0:01:23.322502 seconds ---\n",
      "The final model saved to:  ./save/Krum_0.031_cifar_customized_resnet18_2_1_nParties_3_iid__1000_0_model_2023-09-27T15-10-16.pt\n",
      "Model Saved!\n",
      "filepath  ./save/Krum_0.031_cifar_customized_resnet18_$2_1_nParties_3_iid_1000_0_2023-09-27T15-10-16.out\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 2/2 [01:23<00:00, 41.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output file saved to:  ./save/Krum_0.031_cifar_customized_resnet18_$2_1_nParties_3_iid_1000_0_2023-09-27T15-10-16.out\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.now()\n",
    "img_size = dataset_train[0][0].shape\n",
    "# build model\n",
    "# net_glob = build_model(args, img_size)\n",
    "w_glob = net_glob.state_dict() #w_glob\n",
    "# print(f'w_glob {w_glob}')\n",
    "if args.all_clients: \n",
    "    print(\"Aggregation over all clients\")\n",
    "    w_locals = [w_glob for i in range(args.num_users)]\n",
    "    rounds_train_loss = {user: list() for user in range(args.num_users)}\n",
    "\n",
    "#define the loss function\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "train_loss = []\n",
    "rounds_test_accuracy = []\n",
    "rounds_adv_test_accuracy = []\n",
    "rounds_adv_test_accuracy_2 = []\n",
    "\n",
    "for iter in trange(args.rounds): \n",
    "        \n",
    "    if not args.all_clients:\n",
    "        w_locals = []\n",
    "    \n",
    "    rounds_train_loss = []\n",
    "\n",
    "    # Calculate n and m\n",
    "    n = max(int(args.frac * args.num_users), 1)\n",
    "    m = args.byzantine_threshold\n",
    "\n",
    "    # Generate all possible indices\n",
    "    all_indices = list(range(n))\n",
    "\n",
    "    # Generate attacker indices\n",
    "    attacker_list = np.random.choice(all_indices, m, replace=False)\n",
    "\n",
    "\n",
    "    # Calculate non-attacker indices\n",
    "    idxs_users = list(set(all_indices) - set(attacker_list))\n",
    "\n",
    "    print(\"Attacker Indices:\", attacker_list)\n",
    "    print(\"Non-Attacker Indices:\", idxs_users)\n",
    "\n",
    "    \n",
    "    for idx in idxs_users:\n",
    "        # Local update\n",
    "        local = ModelUpdate(args=args,\n",
    "                            client_id=idx,\n",
    "                            local_ep=args.local_ep, \n",
    "                            dataset=dataset, \n",
    "                            idxs=set(list(dict_users[idx])))\n",
    "        #On each client, compute mini-batch gradient and control variate   \n",
    "        w, loss = local.train(pid=idx, \n",
    "                            round_cur=iter, \n",
    "                            local_net = copy.deepcopy(net_glob).to(args.device), \n",
    "                            net = copy.deepcopy(net_glob).to(args.device))\n",
    "\n",
    "        rounds_train_loss.append(loss) #client level\n",
    "        #Save local model\n",
    "        if args.all_clients:\n",
    "            w_locals[idx] = copy.deepcopy(w)\n",
    "        else:\n",
    "            w_locals.append(copy.deepcopy(w))\n",
    "\n",
    "    for idx in attacker_list:\n",
    "        # Local update\n",
    "        local = ModelUpdate(args=args,\n",
    "                            client_id=idx,\n",
    "                            local_ep=args.local_ep, \n",
    "                            dataset=dataset, \n",
    "                            idxs=set(list(dict_users[idx]))) #Different data\n",
    "        #On each client, compute mini-batch gradient and control variate   \n",
    "        w, loss = local.train(pid=idx, \n",
    "                            round_cur=iter, \n",
    "                            local_net = copy.deepcopy(net_glob).to(args.device), \n",
    "                            net = copy.deepcopy(net_glob).to(args.device))\n",
    "\n",
    "        rounds_train_loss.append(loss) #client level\n",
    "        #Save local model\n",
    "        if args.all_clients:\n",
    "            w_locals[idx] = copy.deepcopy(w)\n",
    "        else:\n",
    "            w_locals.append(copy.deepcopy(w))\n",
    "        \n",
    "    #End on clients\n",
    "    if args.fed == 'scaffold':\n",
    "        w_glob, c_global = FedAvg(w_locals, args, c_global, res_caches) #update at each round\n",
    "    elif args.fed == 'Krum':\n",
    "        w_glob = Krum(w_locals, args)\n",
    "        \n",
    "    elif args.fed == 'CoordinateMedian':\n",
    "        results = CoordinateMedian(w_locals, args)\n",
    "        #manual loading. Prone to issues.\n",
    "        for k, v in zip(w_glob.keys(), results):\n",
    "            # print(f'type v {v}')\n",
    "            if isinstance(v, float):\n",
    "                # print(f'median {v}')\n",
    "                # print(f'w_glob[k] {w_glob[k]}')\n",
    "                pass\n",
    "            else:\n",
    "                v = torch.from_numpy(v) #Create tensors\n",
    "                v = v.to(args.device)\n",
    "                v.requires_grad = True\n",
    "                w_glob[k] = v\n",
    "    else:\n",
    "        w_glob = FedAvg(w_locals, args)\n",
    "    \n",
    "    # try replicate krum with mnist and federated average, using the paper experiment. \n",
    "    # try krum and cifar-10\n",
    "\n",
    "    # copy weight to net_glob\n",
    "    net_glob.load_state_dict(w_glob, strict=True)\n",
    "    \n",
    "    # acc_test, loss_test, adv_acc_test, adv_loss_test = test_img(net_glob, dataset_test, args, criterion)\n",
    "   \n",
    "    train_loss.append(sum(rounds_train_loss))\n",
    "    \n",
    "    acc_test, adv_acc_test, (_) = test_img(net_glob, \n",
    "                                                                     dataset_test, \n",
    "                                                                     test_idxs,\n",
    "                                                                     args, \n",
    "                                                                     criterion)\n",
    "    \n",
    "    accuracy, Gaussian_acc, FGSM_acc_noise, exp_adv_noise = test_img_noise(net_glob, \n",
    "                                                            dataset_test,\n",
    "                                                            test_idxs,\n",
    "                                                            args, \n",
    "                                                            criterion)\n",
    "    \n",
    "    rounds_test_accuracy.append(acc_test)\n",
    "    rounds_adv_test_accuracy.append(adv_acc_test)\n",
    "    rounds_adv_test_accuracy_2.append(FGSM_acc_noise)\n",
    "    \n",
    "    if args.debug:\n",
    "        print(f\"Round: {iter}\")\n",
    "        print(f\"Average train loss over {rounds_train_loss} parties: {sum(rounds_train_loss)}\")\n",
    "        print(f\"Test accuracy: {acc_test}\")\n",
    "        print(f\"Adv Test accuracy: {adv_acc_test}\")\n",
    "        print(f\"Adv Test accuracy With Noise: {FGSM_acc_noise}\")\n",
    "    \n",
    "   \n",
    "\n",
    "    f_model_path = save_model(start_time, args, net_glob, idxs_users)\n",
    "    print('Model Saved!')\n",
    "    \n",
    "     #stopping criteria here. \n",
    "    if exp_adv_noise > args.rho:\n",
    "        print(f'exp_adv_noise {exp_adv_noise}')\n",
    "        print(\"A larger perturbation is required to fool the classifier. Thus, the classifier is more robust.\")\n",
    "        break\n",
    "    save_model_performance(args, start_time, rounds_test_accuracy, \n",
    "                               train_loss, \n",
    "                               rounds_adv_test_accuracy,\n",
    "                           rounds_adv_test_accuracy_2,\n",
    "                               idxs_users)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ecae0d-9084-4d50-a574-a3b7c9e191fa",
   "metadata": {},
   "source": [
    "# Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "bd652bfa-eaf2-4090-99c8-15c9f3a8bcd8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T19:11:39.687416Z",
     "iopub.status.busy": "2023-09-27T19:11:39.687030Z",
     "iopub.status.idle": "2023-09-27T19:11:48.073219Z",
     "shell.execute_reply": "2023-09-27T19:11:48.071883Z",
     "shell.execute_reply.started": "2023-09-27T19:11:39.687374Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is customized_resnet18\n",
      "\n",
      "Test set: \n",
      "Accuracy: 3821/10000 (38.21%)\n",
      "\n",
      "\n",
      "FGSM -- Adversarial Test set as a classifier: \n",
      "Adv Accuracy: 51/10000 (0.51%)\n",
      "\n",
      "\n",
      "Number of correct classified clean examples(as compared to clean predictions): 3821/10000\n",
      "\n",
      "Number of correct classified adversarial examples(as compared to clean predictions): 51/10000\n"
     ]
    }
   ],
   "source": [
    "#Load model\n",
    "# f_model_path='./save/fedavg_0.031_cifar_customized_resnet18_20_5_nParties_5_twoclassnoniid__1000_1.0_model_2023-07-26T22-02-39.pt'\n",
    "net_glob_2 = build_model(args, img_size)\n",
    "weights = torch.load(f_model_path)\n",
    "net_glob_2.load_state_dict(weights) \n",
    "net_glob_2.to(args.device)\n",
    "####\n",
    "test_idxs = np.arange(len(dataset_test))\n",
    "###\n",
    "acc_test, adv_acc_test, (_) = test_img(net_glob_2, \n",
    "                                        dataset_test, \n",
    "                                        test_idxs, \n",
    "                                        args, \n",
    "                                        loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "24103aea-f0a1-46a2-bb6b-fd401dfde319",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T19:11:48.075124Z",
     "iopub.status.busy": "2023-09-27T19:11:48.074889Z",
     "iopub.status.idle": "2023-09-27T19:11:57.690068Z",
     "shell.execute_reply": "2023-09-27T19:11:57.689012Z",
     "shell.execute_reply.started": "2023-09-27T19:11:48.075100Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: \n",
      "Accuracy on benign test examples: 3821/10000 (38.21%)\n",
      "\n",
      "\n",
      "Test set: \n",
      "Accuracy on Gaussin noise test examples: 5/10000 (0.05%)\n",
      "\n",
      "\n",
      "Test accuracy for noisy FGSM: \n",
      "Adv Accuracy: 0.5099999904632568/10000 (0.51%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy, Gaussian_acc, FGSM_acc_noise, exp_adv_noise = test_img_noise(net_glob_2, \n",
    "                                                            dataset_test,\n",
    "                                                            test_idxs,\n",
    "                                                            args, \n",
    "                                                            loss_fn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-torch_13]",
   "language": "python",
   "name": "conda-env-.conda-torch_13-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
